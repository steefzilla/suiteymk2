#!/usr/bin/env bash

# Suitey - Cross-platform test runner
# This file was generated by build.sh - do not edit directly

# Version: 0.1.0
# Built: 2026-01-13 08:50:59 UTC
# Built on: Linux 6.8.0-90-generic

# Included from: src/environment.sh
#!/usr/bin/env bash

# Suitey Environment Validation Functions
# These functions validate that the development and runtime environment
# is properly configured for Suitey to operate correctly.

# Check if Bash version is 4.0 or higher
check_bash_version() {
    local bash_version
    bash_version=$(bash --version | head -n1 | grep -oE '[0-9]+\.[0-9]+' | head -n1)

    if [[ $(echo "$bash_version >= 4.0" | bc -l) -eq 1 ]]; then
        return 0
    else
        echo "Error: Bash version $bash_version is too old. Suitey requires Bash 4.0 or higher." >&2
        echo "Current version: $bash_version" >&2
        echo "Please upgrade Bash to version 4.0 or higher." >&2
        echo "On Ubuntu/Debian: sudo apt-get install bash" >&2
        echo "On macOS with Homebrew: brew install bash" >&2
        return 1
    fi
}

# Check if Docker is installed and accessible
check_docker_installed() {
    if command -v docker >/dev/null 2>&1; then
        return 0
    else
        echo "Error: Docker is not installed. Suitey requires Docker for containerized builds and test execution." >&2
        echo "Please install Docker:" >&2
        echo "  - Ubuntu/Debian: sudo apt-get install docker.io" >&2
        echo "  - CentOS/RHEL: sudo yum install docker" >&2
        echo "  - macOS: Download from https://www.docker.com/products/docker-desktop" >&2
        echo "  - Windows: Download from https://www.docker.com/products/docker-desktop" >&2
        return 1
    fi
}

# Check if Docker daemon is running
check_docker_daemon_running() {
    if docker info >/dev/null 2>&1; then
        return 0
    else
        echo "Error: Docker daemon is not running. Suitey requires a running Docker daemon." >&2
        echo "Please start Docker:" >&2
        echo "  - Linux: sudo systemctl start docker (or sudo service docker start)" >&2
        echo "  - macOS/Windows: Start Docker Desktop application" >&2
        echo "  - Or run: sudo dockerd (in a separate terminal)" >&2
        return 1
    fi
}

# Check if required directories exist
check_required_directories() {
    local dirs=("src" "tests/bats" "mod")
    local missing_dirs=()

    for dir in "${dirs[@]}"; do
        if [[ ! -d "$dir" ]]; then
            missing_dirs+=("$dir")
        fi
    done

    if [[ ${#missing_dirs[@]} -eq 0 ]]; then
        return 0
    else
        echo "Error: Required directories are missing: ${missing_dirs[*]}" >&2
        echo "Please create the missing directories:" >&2
        for dir in "${missing_dirs[@]}"; do
            echo "  mkdir -p $dir" >&2
        done
        return 1
    fi
}

# Check if /tmp directory is writable
check_tmp_writable() {
    if [[ -w "/tmp" ]]; then
        return 0
    else
        echo "Error: /tmp directory is not writable. Suitey requires write access to /tmp for temporary files." >&2
        echo "Please check /tmp permissions:" >&2
        echo "  ls -ld /tmp" >&2
        echo "If permissions are incorrect, you may need to:" >&2
        echo "  sudo chmod 1777 /tmp" >&2
        return 1
    fi
}

# Check if required test dependencies are available
check_test_dependencies() {
    local deps=("bats")
    local missing_deps=()

    for dep in "${deps[@]}"; do
        if ! command -v "$dep" >/dev/null 2>&1; then
            missing_deps+=("$dep")
        fi
    done

    # Check for bats-support and bats-assert libraries
    if [[ ! -f "tests/bats/unit/test_helper/bats-support/load.bash" ]]; then
        missing_deps+=("bats-support")
    fi

    if [[ ! -f "tests/bats/unit/test_helper/bats-assert/load.bash" ]]; then
        missing_deps+=("bats-assert")
    fi

    if [[ ${#missing_deps[@]} -eq 0 ]]; then
        return 0
    else
        echo "Error: Required test dependencies are missing: ${missing_deps[*]}" >&2
        echo "Please install the missing dependencies:" >&2

        for dep in "${missing_deps[@]}"; do
            case "$dep" in
                "bats")
                    echo "  - BATS testing framework:" >&2
                    echo "    Ubuntu/Debian: sudo apt-get install bats" >&2
                    echo "    macOS: brew install bats-core" >&2
                    echo "    Or download from: https://github.com/bats-core/bats-core" >&2
                    ;;
                "bats-support")
                    echo "  - bats-support library:" >&2
                    echo "    This dependency is now automatically managed as a git submodule." >&2
                    echo "    Use 'git submodule update --init --recursive' if missing." >&2
                    ;;
                "bats-assert")
                    echo "  - bats-assert library:" >&2
                    echo "    This dependency is now automatically managed as a git submodule." >&2
                    echo "    Use 'git submodule update --init --recursive' if missing." >&2
                    ;;
            esac
        done

        return 1
    fi
}

# Check if files can be created in /tmp directory
create_test_file_in_tmp() {
    local test_file="/tmp/suitey_test_file_$$"

    # Try to create a test file in /tmp
    if echo "test content" > "$test_file" 2>/dev/null; then
        # Clean up the test file
        rm -f "$test_file"
        return 0
    else
        echo "Error: Cannot create files in /tmp directory. Suitey requires write access to /tmp." >&2
        return 1
    fi
}

# Verify that filesystem isolation principle is maintained
verify_filesystem_isolation_principle() {
    # This function verifies that Suitey respects filesystem isolation
    # Suitey should only write to /tmp, not modify the project directory
    local project_dir
    project_dir="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"

    # Check that project directory exists and is accessible for reading
    if [[ -d "$project_dir" && -r "$project_dir" ]]; then
        # Project directory should be readable for Suitey to function
        # The isolation principle means Suitey won't write here during execution
        return 0
    else
        echo "Error: Project directory is not accessible. This may indicate permission issues." >&2
        return 1
    fi
}

# Check if temporary directories can be created in /tmp
create_test_directory_in_tmp() {
    local test_dir="/tmp/suitey_test_dir_$$"

    # Try to create a test directory in /tmp
    if mkdir "$test_dir" 2>/dev/null; then
        # Clean up the test directory
        rmdir "$test_dir"
        return 0
    else
        echo "Error: Cannot create directories in /tmp. Suitey requires write access to /tmp for temporary directories." >&2
        return 1
    fi
}

# Verify that environment checks respect filesystem isolation principle
verify_environment_filesystem_isolation() {
    # This function verifies that all environment validation functions
    # only access /tmp and don't modify the project directory
    local project_dir
    project_dir="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"

    # Use a lighter approach - check for temporary files created outside /tmp
    # instead of full checksum comparison
    local temp_files_before
    temp_files_before=$(find "$project_dir" -name "suitey_*" -type f 2>/dev/null | wc -l)

    # Run all environment validation functions
    check_bash_version >/dev/null 2>&1
    check_docker_installed >/dev/null 2>&1
    check_docker_daemon_running >/dev/null 2>&1
    check_required_directories >/dev/null 2>&1
    check_tmp_writable >/dev/null 2>&1
    check_test_dependencies >/dev/null 2>&1

    local temp_files_after
    temp_files_after=$(find "$project_dir" -name "suitey_*" -type f 2>/dev/null | wc -l)

    # Verify that no suitey temporary files were created in project directory
    if [[ "$temp_files_before" -eq "$temp_files_after" ]]; then
        return 0
    else
        echo "Error: Environment validation functions created files outside /tmp. This violates filesystem isolation." >&2
        return 1
    fi
}
# End of: src/environment.sh

# Included from: src/build_system_detector.sh
#!/usr/bin/env bash

# Build System Detector
# Determines if and how projects need to be built before testing
# Aggregates build requirements from all detected platforms
#
# Filesystem Isolation: This module only reads from project directories.
# Build execution happens in isolated Docker containers with read-only
# project access. No modifications are made to the project filesystem.

# Source required dependencies
source "src/data_access.sh" 2>/dev/null || true

# Detect build requirements for detected platforms
# Usage: detect_build_requirements <platform_data>
# Returns: Build requirements in flat data format
# Behavior: Calls detect_build_requirements on each detected platform's module
detect_build_requirements() {
    local platform_data="$1"

    # Initialize result data
    local result=""
    local requires_build=false
    local total_build_commands_count=0
    local total_build_dependencies_count=0
    local total_build_artifacts_count=0

    # Parse platform data to get platforms count
    local platforms_count
    platforms_count=$(data_get "$platform_data" "platforms_count")

    if [[ -z "$platforms_count" ]] || [[ "$platforms_count" -eq 0 ]]; then
        # No platforms detected, no build required
        result="requires_build=false"$'\n'
        result="${result}build_commands_count=0"$'\n'
        result="${result}build_dependencies_count=0"$'\n'
        result="${result}build_artifacts_count=0"
        echo "$result"
        return 0
    fi

    # Process each detected platform
    local i=0
    while [[ $i -lt "$platforms_count" ]]; do
        local language
        local framework
        local module_type

        language=$(data_get "$platform_data" "platforms_${i}_language")
        framework=$(data_get "$platform_data" "platforms_${i}_framework")
        module_type=$(data_get "$platform_data" "platforms_${i}_module_type")

        # Determine module file path based on platform type
        local module_file=""
        case "$module_type" in
            "language")
                module_file="mod/languages/${language}/mod.sh"
                ;;
            "framework")
                module_file="mod/frameworks/${framework}/mod.sh"
                ;;
            "tool")
                module_file="mod/tools/${framework}/mod.sh"
                ;;
        esac

        # If module file exists, load it in a subshell to avoid function conflicts
        if [[ -n "$module_file" ]] && [[ -f "$module_file" ]]; then
            # Get the project root from the platform data
            local project_root
            project_root=$(data_get "$platform_data" "project_root" || echo ".")

            # Execute the module's detect_build_requirements in a subshell
            local module_result
            module_result=$(bash -c "
                source '$module_file' 2>/dev/null
                detect_build_requirements '$project_root' '$platform_data' 2>/dev/null
            " || echo "requires_build=false")

            # Check if this platform requires building
            local platform_requires_build
            platform_requires_build=$(echo "$module_result" | grep "^requires_build=" | cut -d'=' -f2 || echo "false")

            if [[ "$platform_requires_build" == "true" ]]; then
                requires_build=true

                # Aggregate build commands
                local build_commands_count
                build_commands_count=$(echo "$module_result" | grep "^build_commands_count=" | cut -d'=' -f2 || echo "0")

                local j=0
                while [[ $j -lt "$build_commands_count" ]]; do
                    local build_command
                    build_command=$(echo "$module_result" | grep "^build_commands_${j}=" | cut -d'=' -f2 || echo "")

                    if [[ -n "$build_command" ]]; then
                        result=$(data_set "$result" "build_commands_${total_build_commands_count}" "$build_command")
                        ((total_build_commands_count++))
                    fi
                    ((j++))
                done

                # Aggregate build dependencies
                local build_dependencies_count
                build_dependencies_count=$(echo "$module_result" | grep "^build_dependencies_count=" | cut -d'=' -f2 || echo "0")

                local j=0
                while [[ $j -lt "$build_dependencies_count" ]]; do
                    local build_dependency
                    build_dependency=$(echo "$module_result" | grep "^build_dependencies_${j}=" | cut -d'=' -f2 || echo "")

                    if [[ -n "$build_dependency" ]]; then
                        result=$(data_set "$result" "build_dependencies_${total_build_dependencies_count}" "$build_dependency")
                        ((total_build_dependencies_count++))
                    fi
                    ((j++))
                done

                # Aggregate build artifacts
                local build_artifacts_count
                build_artifacts_count=$(echo "$module_result" | grep "^build_artifacts_count=" | cut -d'=' -f2 || echo "0")

                local j=0
                while [[ $j -lt "$build_artifacts_count" ]]; do
                    local build_artifact
                    build_artifact=$(echo "$module_result" | grep "^build_artifacts_${j}=" | cut -d'=' -f2 || echo "")

                    if [[ -n "$build_artifact" ]]; then
                        result=$(data_set "$result" "build_artifacts_${total_build_artifacts_count}" "$build_artifact")
                        ((total_build_artifacts_count++))
                    fi
                    ((j++))
                done
            fi
        fi

        ((i++))
    done

    # Set final results
    result=$(data_set "$result" "requires_build" "$requires_build")
    result=$(data_set "$result" "build_commands_count" "$total_build_commands_count")
    result=$(data_set "$result" "build_dependencies_count" "$total_build_dependencies_count")
    result=$(data_set "$result" "build_artifacts_count" "$total_build_artifacts_count")

    echo "$result"
    return 0
}

# Get detailed build steps for detected platforms
# Usage: get_build_steps <platform_data> <build_requirements>
# Returns: Detailed build steps in flat data format
# Behavior: Returns containerized build specifications. Build execution
#           happens in isolated Docker containers with read-only project
#           access. Project directories are never modified.
get_build_steps() {
    local platform_data="$1"
    local build_requirements="$2"

    # Initialize result data
    local result=""
    local total_build_steps_count=0

    # Parse platform data to get platforms count
    local platforms_count
    platforms_count=$(data_get "$platform_data" "platforms_count")

    if [[ -z "$platforms_count" ]] || [[ "$platforms_count" -eq 0 ]]; then
        # No platforms detected, no build steps
        result="build_steps_count=0"
        echo "$result"
        return 0
    fi

    # Check if building is required overall
    local requires_build
    requires_build=$(echo "$build_requirements" | grep "^requires_build=" | cut -d'=' -f2 || echo "false")

    if [[ "$requires_build" != "true" ]]; then
        result="build_steps_count=0"
        echo "$result"
        return 0
    fi

    # Process each detected platform
    local i=0
    while [[ $i -lt "$platforms_count" ]]; do
        local language
        local framework
        local module_type

        language=$(data_get "$platform_data" "platforms_${i}_language")
        framework=$(data_get "$platform_data" "platforms_${i}_framework")
        module_type=$(data_get "$platform_data" "platforms_${i}_module_type")

        # Determine module file path based on platform type
        local module_file=""
        case "$module_type" in
            "language")
                module_file="mod/languages/${language}/mod.sh"
                ;;
            "framework")
                module_file="mod/frameworks/${framework}/mod.sh"
                ;;
            "tool")
                module_file="mod/tools/${framework}/mod.sh"
                ;;
        esac

        # If module file exists, load it in a subshell to avoid function conflicts
        if [[ -n "$module_file" ]] && [[ -f "$module_file" ]]; then
            # Get the project root from the platform data
            local project_root
            project_root=$(data_get "$platform_data" "project_root" || echo ".")

            # Execute the module's get_build_steps in a subshell
            local module_result
            module_result=$(bash -c "
                source '$module_file' 2>/dev/null
                get_build_steps '$project_root' '$build_requirements' 2>/dev/null
            " || echo "build_steps_count=0")

            # Check if this platform has build steps
            local build_steps_count
            build_steps_count=$(echo "$module_result" | grep "^build_steps_count=" | cut -d'=' -f2 || echo "0")

            local j=0
            while [[ $j -lt "$build_steps_count" ]]; do
                # Copy all build step data with updated index
                local step_prefix="build_steps_${j}"
                local new_step_prefix="build_steps_${total_build_steps_count}"

                # Get all lines for this build step
                local step_lines
                step_lines=$(echo "$module_result" | grep "^${step_prefix}_")

                # Add each line with updated index
                while IFS= read -r line; do
                    if [[ -n "$line" ]]; then
                        local new_line="${line/${step_prefix}_/${new_step_prefix}_}"
                        result=$(data_set "$result" "${new_line%%=*}" "${new_line#*=}")
                    fi
                done <<< "$step_lines"

                ((total_build_steps_count++))
                ((j++))
            done
        fi

        ((i++))
    done

    # Set final results
    result=$(data_set "$result" "build_steps_count" "$total_build_steps_count")

    echo "$result"
    return 0
}

# Analyze dependencies between build steps
# Usage: analyze_build_dependencies <build_steps>
# Returns: Dependency analysis in flat data format
# Behavior: Analyzes build step dependencies and determines execution order
analyze_build_dependencies() {
    local build_steps="$1"

    # Initialize result data
    local result=""
    local execution_order=""
    local parallel_groups_count=0
    local dependency_graph=""

    # Parse build steps count
    local build_steps_count
    build_steps_count=$(echo "$build_steps" | grep "^build_steps_count=" | cut -d'=' -f2 || echo "0")

    if [[ -z "$build_steps_count" ]] || [[ "$build_steps_count" -eq 0 ]]; then
        # No build steps, no dependencies to analyze
        result="execution_order_count=0"$'\n'
        result="${result}parallel_groups_count=0"$'\n'
        result="${result}dependency_graph_count=0"
        echo "$result"
        return 0
    fi

    # For now, implement a simple dependency analysis
    # In a real implementation, this would analyze actual dependencies between build steps
    # For this phase, we'll assume all build steps can run in parallel (no dependencies)

    # Create execution order (simple sequential for now)
    local execution_order_list=""
    local i=0
    while [[ $i -lt "$build_steps_count" ]]; do
        if [[ -n "$execution_order_list" ]]; then
            execution_order_list="${execution_order_list},"
        fi
        execution_order_list="${execution_order_list}${i}"
        ((i++))
    done

    result="execution_order_count=${build_steps_count}"$'\n'
    result="${result}execution_order_steps=${execution_order_list}"$'\n'

    # For now, assume all builds can run in parallel (no dependencies)
    # In a real implementation, this would analyze dependencies and create groups
    result="${result}parallel_groups_count=1"$'\n'
    result="${result}parallel_groups_0_step_count=${build_steps_count}"$'\n'
    result="${result}parallel_groups_0_steps=${execution_order_list}"$'\n'

    # Simple dependency graph (no dependencies for now)
    result="${result}dependency_graph_count=0"

    echo "$result"
    return 0
}

# End of: src/build_system_detector.sh

# Included from: src/data_access.sh
#!/usr/bin/env bash

# Suitey Data Access Functions
# Pure Bash data manipulation utilities for the flat data format
# No external dependencies

# Extract a value from data using a key path
# Usage: data_get <data> <key>
# Returns: Extracted value as string, or empty string if not found
# Exit code: 0 on success, 1 on error (empty inputs)
data_get() {
    local data="$1"
    local key="$2"

    # Validate inputs
    if [[ -z "$data" ]] || [[ -z "$key" ]]; then
        return 1
    fi

    # Search for the first occurrence of key= in the data
    local line
    line=$(echo "$data" | grep -m 1 "^${key}=" || true)

    # If not found, return empty string
    if [[ -z "$line" ]]; then
        echo ""
        return 0
    fi

    # Extract value after the = sign
    local value="${line#${key}=}"

    # Remove surrounding quotes if present (both double and single quotes)
    # This handles values like "quoted value" or 'single quoted'
    if [[ "$value" =~ ^\".*\"$ ]]; then
        # Remove double quotes
        value="${value#\"}"
        value="${value%\"}"
    elif [[ "$value" =~ ^\'.*\'$ ]]; then
        # Remove single quotes
        value="${value#\'}"
        value="${value%\'}"
    fi

    # Output the value
    echo "$value"
    return 0
}

# Extract an array element from data by index
# Usage: data_get_array <data> <array_name> <index>
# Returns: Array element value, or empty if not found
# Exit code: 0 on success, 1 on error (invalid inputs)
# Behavior: Constructs key as ${array_name}_${index} and calls data_get()
data_get_array() {
    local data="$1"
    local array_name="$2"
    local index="$3"

    # Validate inputs
    if [[ -z "$data" ]] || [[ -z "$array_name" ]] || [[ -z "$index" ]]; then
        return 1
    fi

    # Validate index is numeric (0-based, non-negative integer)
    if ! [[ "$index" =~ ^[0-9]+$ ]]; then
        return 1
    fi

    # Construct key as ${array_name}_${index} (e.g., "test_files_0")
    local key="${array_name}_${index}"

    # Call data_get() with the constructed key
    data_get "$data" "$key"
    return $?
}

# Get the count of elements in an array
# Usage: data_array_count <data> <array_name>
# Returns: Array count as integer string, or "0" if not found/invalid
# Exit code: 0 on success, 1 if inputs are empty
# Behavior: Looks for ${array_name}_count key and validates it's numeric
data_array_count() {
    local data="$1"
    local array_name="$2"

    # Validate inputs
    if [[ -z "$data" ]] || [[ -z "$array_name" ]]; then
        return 1
    fi

    # Look for ${array_name}_count key (e.g., "test_files_count")
    local count_key="${array_name}_count"
    local count_value
    count_value=$(data_get "$data" "$count_key")

    # If not found, return "0"
    if [[ -z "$count_value" ]]; then
        echo "0"
        return 0
    fi

    # Validate that the value is numeric (non-negative integer)
    if ! [[ "$count_value" =~ ^[0-9]+$ ]]; then
        echo "0"
        return 0
    fi

    # Return the count
    echo "$count_value"
    return 0
}

# Extract all elements from an array
# Usage: data_get_array_all <data> <array_name>
# Returns: Array elements, one per line (stdout), or empty if array doesn't exist
# Exit code: 0 on success
# Behavior: Gets array count, then iterates from 0 to count-1, calling data_get_array() for each index
data_get_array_all() {
    local data="$1"
    local array_name="$2"

    # Validate inputs (but don't fail - return empty if invalid)
    if [[ -z "$data" ]] || [[ -z "$array_name" ]]; then
        return 0
    fi

    # Get array count using data_array_count()
    local count
    count=$(data_array_count "$data" "$array_name")

    # If count is 0, return empty (no elements to return)
    if [[ "$count" == "0" ]]; then
        return 0
    fi

    # Iterate from 0 to count-1, retrieving each element
    local i=0
    while [[ $i -lt $count ]]; do
        # Get array element at index i using data_get_array()
        local element
        element=$(data_get_array "$data" "$array_name" "$i")
        echo "$element"
        i=$((i + 1))
    done

    return 0
}

# Set a value in data, creating new data with updated value
# Usage: data_set <data> <key> <value>
# Returns: Updated data string (stdout)
# Exit code: 0 on success, 1 if key is empty
# Behavior: Removes existing key if present, escapes value if needed, appends new key-value pair
data_set() {
    local data="$1"
    local key="$2"
    local value="$3"

    # Validate key is not empty
    if [[ -z "$key" ]]; then
        return 1
    fi

    # Remove existing key if present (including multi-line heredoc blocks)
    # Remove lines matching "^${key}="
    local filtered_data
    filtered_data=$(echo "$data" | grep -v "^${key}=" || true)
    
    # Remove heredoc blocks for this key (lines between "${key}<<EOF" and "EOF")
    local cleaned_data=""
    local in_heredoc=false
    local heredoc_start="${key}<<EOF"
    
    while IFS= read -r line || [[ -n "$line" ]]; do
        # Check if line starts with heredoc marker
        local line_prefix="${line%%<<*}"
        if [[ "$line_prefix" == "$key" ]] && [[ "$line" == *"<<"* ]]; then
            in_heredoc=true
            continue
        fi
        
        # Check if we're ending a heredoc block
        if [[ "$in_heredoc" == true ]] && [[ "$line" == "EOF" ]]; then
            in_heredoc=false
            continue
        fi
        
        # Only include lines that are not part of a heredoc block
        if [[ "$in_heredoc" == false ]]; then
            if [[ -n "$cleaned_data" ]]; then
                cleaned_data="${cleaned_data}"$'\n'"${line}"
            else
                cleaned_data="${line}"
            fi
        fi
    done <<< "$filtered_data"
    
    # If cleaned_data is empty, use filtered_data
    if [[ -z "$cleaned_data" ]]; then
        cleaned_data="$filtered_data"
    fi

    # Escape value if it contains special characters (spaces, $, `, ", \)
    local escaped_value="$value"
    # Check if value contains special characters that need escaping
    if [[ "$value" =~ [[:space:]] ]] || [[ "$value" =~ \$ ]] || [[ "$value" =~ \` ]] || [[ "$value" =~ \" ]] || [[ "$value" =~ \\ ]]; then
        # Wrap in quotes and escape internal quotes and backslashes
        escaped_value=$(echo "$value" | sed 's/\\/\\\\/g; s/"/\\"/g')
        escaped_value="\"${escaped_value}\""
    fi

    # Append new key-value pair to data
    local result
    if [[ -n "$cleaned_data" ]]; then
        result="${cleaned_data}"$'\n'"${key}=${escaped_value}"
    else
        result="${key}=${escaped_value}"
    fi

    # Output the updated data
    echo "$result"
    return 0
}

# Append a value to an array
# Usage: data_array_append <data> <array_name> <value>
# Returns: Updated data string with new array element
# Exit code: 0 on success
# Behavior: Gets current count, sets new element at index count, updates count to count+1
data_array_append() {
    local data="$1"
    local array_name="$2"
    local value="$3"

    # Get current array count
    local count
    count=$(data_array_count "$data" "$array_name")
    
    # If count failed or returned error, default to 0
    if [[ $? -ne 0 ]] || [[ -z "$count" ]]; then
        count=0
    fi

    # Set new element at index count using data_set()
    data=$(data_set "$data" "${array_name}_${count}" "$value")

    # Update count to count + 1 using data_set()
    local new_count=$((count + 1))
    data=$(data_set "$data" "${array_name}_count" "$new_count")

    # Return updated data string
    echo "$data"
    return 0
}

# Set an entire array, replacing any existing array entries
# Usage: data_set_array <data> <array_name> <value1> [value2] [value3] ...
# Returns: Updated data string
# Exit code: 0 on success
# Behavior: Removes all existing array entries, adds new entries at sequential indices
data_set_array() {
    local data="$1"
    local array_name="$2"
    shift 2  # Remove first two arguments, leaving only values

    # Get current count to know how many entries to remove
    local old_count
    old_count=$(data_array_count "$data" "$array_name")
    
    # Remove all existing array entries (${array_name}_N= and ${array_name}_count=)
    # Remove entries from 0 to old_count-1
    if [[ "$old_count" -gt 0 ]]; then
        local i=0
        while [[ $i -lt $old_count ]]; do
            # Remove the array element line
            data=$(echo "$data" | grep -v "^${array_name}_${i}=" || true)
            i=$((i + 1))
        done
    fi
    
    # Remove the count line
    data=$(echo "$data" | grep -v "^${array_name}_count=" || true)
    
    # Remove empty lines that might have been created
    data=$(echo "$data" | grep -v "^$" || true)
    
    # If data is now empty or only whitespace, reset it
    if [[ -z "${data// }" ]]; then
        data=""
    fi

    # Add new entries for each value at sequential indices
    local index=0
    local values=("$@")
    
    for value in "${values[@]}"; do
        data=$(data_set "$data" "${array_name}_${index}" "$value")
        index=$((index + 1))
    done

    # Set count to number of values added
    data=$(data_set "$data" "${array_name}_count" "$index")

    # Return updated data string
    echo "$data"
    return 0
}

# Set a multi-line value using heredoc syntax
# Usage: data_set_multiline <data> <key> <value>
# Returns: Updated data string with heredoc syntax
# Exit code: 0 on success
# Behavior: Removes existing heredoc block or regular key=value entry, appends new heredoc block
data_set_multiline() {
    local data="$1"
    local key="$2"
    local value="$3"

    # Validate key is not empty
    if [[ -z "$key" ]]; then
        return 1
    fi

    # Remove existing heredoc block if present (lines between `${key}<<EOF` and `EOF`)
    # Also remove regular key=value entry for this key
    local cleaned_data=""
    local in_heredoc=false
    
    while IFS= read -r line || [[ -n "$line" ]]; do
        # Check if line starts with heredoc marker for this key (e.g., "key<<EOF")
        if [[ "${line%%<<*}" == "$key" ]] && [[ "$line" == *"<<"* ]]; then
            in_heredoc=true
            continue
        fi
        
        # Check if we're ending a heredoc block
        if [[ "$in_heredoc" == true ]] && [[ "$line" == "EOF" ]]; then
            in_heredoc=false
            continue
        fi
        
        # Skip lines that are part of a heredoc block
        if [[ "$in_heredoc" == true ]]; then
            continue
        fi
        
        # Skip regular key=value entry for this key
        if [[ "$line" =~ ^${key}= ]]; then
            continue
        fi
        
        # Include all other lines
        if [[ -n "$cleaned_data" ]]; then
            cleaned_data="${cleaned_data}"$'\n'"${line}"
        else
            cleaned_data="${line}"
        fi
    done <<< "$data"
    
    # If cleaned_data is empty, reset it
    if [[ -z "${cleaned_data// }" ]]; then
        cleaned_data=""
    fi

    # Append new heredoc block: `${key}<<EOF`, value lines, `EOF`
    local result
    if [[ -n "$cleaned_data" ]]; then
        result="${cleaned_data}"$'\n'"${key}<<EOF"
    else
        result="${key}<<EOF"
    fi
    
    # Add value lines if not empty
    if [[ -n "$value" ]]; then
        result="${result}"$'\n'"${value}"
    fi
    
    # Add EOF marker
    result="${result}"$'\n'"EOF"

    # Output the updated data
    echo "$result"
    return 0
}

# Get a multi-line value, handling heredoc syntax
# Usage: data_get_multiline <data> <key>
# Returns: Multi-line value (without heredoc markers), or single-line value
# Exit code: 0 on success, 1 on error (invalid inputs)
# Behavior: Checks if key uses heredoc syntax, extracts content between markers or calls data_get()
data_get_multiline() {
    local data="$1"
    local key="$2"

    # Validate inputs
    if [[ -z "$data" ]] || [[ -z "$key" ]]; then
        return 1
    fi

    # Check if key uses heredoc syntax (`${key}<<EOF`)
    local in_heredoc=false
    local heredoc_content=""
    
    while IFS= read -r line || [[ -n "$line" ]]; do
        # Check if line starts with heredoc marker for this key (e.g., "key<<EOF")
        if [[ "${line%%<<*}" == "$key" ]] && [[ "$line" == *"<<"* ]]; then
            in_heredoc=true
            continue
        fi
        
        # Check if we're ending a heredoc block
        if [[ "$in_heredoc" == true ]] && [[ "$line" == "EOF" ]]; then
            # Found complete heredoc block, return content
            echo "$heredoc_content"
            return 0
        fi
        
        # Collect content between heredoc markers
        if [[ "$in_heredoc" == true ]]; then
            if [[ -n "$heredoc_content" ]]; then
                heredoc_content="${heredoc_content}"$'\n'"${line}"
            else
                heredoc_content="${line}"
            fi
        fi
    done <<< "$data"
    
    # If we were in a heredoc but didn't find EOF, return what we collected
    if [[ "$in_heredoc" == true ]]; then
        echo "$heredoc_content"
        return 0
    fi
    
    # If not heredoc, call data_get() for regular single-line value
    data_get "$data" "$key"
    return $?
}

# Validate that a string conforms to the data format specification
# Usage: data_validate <data>
# Exit code: 0 if valid data format, 1 if invalid
# Behavior: Validates each line against allowed patterns (key=value, comments, sections, heredoc)
data_validate() {
    local data="$1"

    # Empty input is considered valid
    if [[ -z "$data" ]]; then
        return 0
    fi

    # Validate each line
    local in_heredoc=false
    while IFS= read -r line || [[ -n "$line" ]]; do
        # Skip empty lines
        if [[ -z "${line// }" ]]; then
            continue
        fi

        # Allow comment lines (starting with #)
        if [[ "$line" =~ ^# ]]; then
            continue
        fi

        # Allow section headers ([section_name])
        if [[ "$line" =~ ^\[.*\]$ ]]; then
            continue
        fi

        # Allow heredoc start markers (key<<EOF)
        # Check if line contains << and doesn't start with =
        if [[ "$line" == *"<<"* ]] && [[ "$line" != "="* ]]; then
            in_heredoc=true
            continue
        fi

        # Allow heredoc end markers (EOF)
        if [[ "$line" == "EOF" ]]; then
            in_heredoc=false
            continue
        fi

        # Skip validation for lines inside heredoc blocks
        if [[ "$in_heredoc" == true ]]; then
            continue
        fi

        # Require other lines to match key=value pattern
        if [[ ! "$line" =~ ^[^=]+= ]]; then
            return 1
        fi
    done <<< "$data"

    # All lines are valid
    return 0
}

# Check if a key exists in data
# Usage: data_has_key <data> <key>
# Exit code: 0 if key exists, 1 if not found or invalid inputs
# Behavior: Searches for lines starting with ${key}=
data_has_key() {
    local data="$1"
    local key="$2"

    # Validate inputs
    if [[ -z "$data" ]] || [[ -z "$key" ]]; then
        return 1
    fi

    # Search for lines starting with ${key}=
    # Use grep to find exact match (key= at start of line)
    if echo "$data" | grep -q "^${key}="; then
        return 0
    fi

    # Key not found
    return 1
}

# End of: src/data_access.sh

# Included from: src/mod_registry.sh
#!/usr/bin/env bash

# Suitey Modules Registry
# Centralized registry for Suitey Modules with registration, lookup, and lifecycle management
# No external dependencies

# Registry storage (using associative arrays)
declare -A MODULE_REGISTRY
declare -A MODULE_METADATA

# Required interface methods that all modules must implement
readonly REQUIRED_METHODS=(
    "detect"
    "check_binaries"
    "discover_test_suites"
    "detect_build_requirements"
    "get_build_steps"
    "execute_test_suite"
    "parse_test_results"
    "get_metadata"
)

# Reset the registry (for testing)
reset_registry() {
    # Clear arrays (use -g to ensure we're modifying global arrays)
    unset MODULE_REGISTRY MODULE_METADATA
    declare -gA MODULE_REGISTRY
    declare -gA MODULE_METADATA
}

# Validate that a module implements all required interface methods
# Usage: validate_module_interface
# Exit code: 0 if valid, 1 if invalid
# Note: This should be called after sourcing a module script
validate_module_interface() {
    # Check if all required methods exist as functions
    for method in "${REQUIRED_METHODS[@]}"; do
        # Check if method exists as a function
        if ! declare -f "$method" >/dev/null 2>&1; then
            return 1
        fi
    done

    return 0
}

# Validate module metadata structure
# Usage: validate_module_metadata <metadata_data>
# Exit code: 0 if valid, 1 if invalid
validate_module_metadata() {
    local metadata="$1"

    # Basic validation: check that metadata is not empty
    if [[ -z "$metadata" ]]; then
        return 1
    fi

    # Check for required fields (can be lenient for now)
    # At minimum, should have language field (for backward compatibility)
    # module_type is optional but recommended
    if ! echo "$metadata" | grep -q "^language="; then
        return 1
    fi

    return 0
}

# Validate module method signature (parameter count)
# Usage: validate_module_method_signature <method_name> <expected_param_count>
# Exit code: 0 if valid, 1 if invalid
# Note: In Bash, we can't easily check parameter count at runtime without calling the function
# This is a placeholder for signature validation - actual validation would require static analysis
validate_module_method_signature() {
    local method_name="$1"
    local expected_param_count="$2"

    # Check if method exists
    if ! declare -f "$method_name" >/dev/null 2>&1; then
        return 1
    fi

    # In Bash, we can't easily check parameter count without parsing the function definition
    # For now, we just verify the method exists
    # Full signature validation would require parsing the function definition
    return 0
}

# Validate module return format (flat data format)
# Usage: validate_module_return_format <return_value>
# Exit code: 0 if valid flat data format, 1 if invalid
validate_module_return_format() {
    local return_value="$1"

    # Empty return is valid (methods may return empty when not applicable)
    if [[ -z "$return_value" ]]; then
        return 0
    fi

    # Check if return value contains key=value pairs (flat data format)
    # Should not contain JSON-like structures
    if echo "$return_value" | grep -q '[{}]'; then
        # Contains braces, likely JSON - invalid
        return 1
    fi

    # Check if it contains at least one key=value pair
    if ! echo "$return_value" | grep -q "^[^=]*="; then
        # No key=value pairs found - may be invalid
        # But allow empty or single-line values
        if [[ -n "${return_value// }" ]]; then
            # Non-empty but no = sign - might be invalid
            # For now, be lenient and allow it
            return 0
        fi
    fi

    return 0
}

# Perform complete interface validation for a module
# Usage: validate_module_interface_complete <identifier>
# Exit code: 0 if valid, 1 if invalid
validate_module_interface_complete() {
    local identifier="$1"

    if [[ -z "$identifier" ]]; then
        echo "Error: Module identifier cannot be empty" >&2
        return 1
    fi

    # Check if module is registered
    if [[ -z "${MODULE_REGISTRY[$identifier]}" ]]; then
        echo "Error: Module '$identifier' is not registered" >&2
        return 1
    fi

    # Validate all required methods exist
    if ! validate_module_interface; then
        echo "Error: Module '$identifier' does not implement all required methods" >&2
        return 1
    fi

    # Validate each method's return format (sample validation)
    # For detect() method
    if declare -f "detect" >/dev/null 2>&1; then
        local sample_result
        sample_result=$(detect "/tmp" 2>/dev/null || echo "")
        if ! validate_module_return_format "$sample_result"; then
            echo "Error: Module '$identifier' method 'detect()' returns invalid format" >&2
            return 1
        fi
    fi

    # Validate get_metadata() return format
    if declare -f "get_metadata" >/dev/null 2>&1; then
        local metadata
        metadata=$(get_metadata 2>/dev/null || echo "")
        if ! validate_module_return_format "$metadata"; then
            echo "Error: Module '$identifier' method 'get_metadata()' returns invalid format" >&2
            return 1
        fi
    fi

    return 0
}

# Register a Suitey module
# Usage: register_module <identifier> <module_name>
# Exit code: 0 on success, 1 on error
# Note: Module should be sourced before calling this function
register_module() {
    local identifier="$1"
    local module_name="$2"

    # Validate identifier is not empty
    if [[ -z "$identifier" ]]; then
        echo "Error: Module identifier cannot be empty" >&2
        return 1
    fi

    # Check if module is already registered
    if [[ -n "${MODULE_REGISTRY[$identifier]}" ]]; then
        echo "Error: Module with identifier '$identifier' is already registered" >&2
        return 1
    fi

    # Validate module interface (check if required methods exist as functions)
    # Modules are sourced before registration, so functions should be available
    local interface_valid=true
    for method in "${REQUIRED_METHODS[@]}"; do
        # Check if method exists as a function
        if ! declare -f "$method" >/dev/null 2>&1; then
            echo "Error: Module '$identifier' is missing required method '$method'" >&2
            interface_valid=false
        fi
    done

    if [[ "$interface_valid" == false ]]; then
        return 1
    fi

    # Get module metadata
    local metadata=""
    if declare -f "get_metadata" >/dev/null 2>&1; then
        metadata=$(get_metadata)
    else
        echo "Error: Module '$identifier' does not provide get_metadata() method" >&2
        return 1
    fi

    # Validate metadata
    if ! validate_module_metadata "$metadata"; then
        echo "Error: Module '$identifier' has invalid metadata" >&2
        return 1
    fi

    # Register the module
    MODULE_REGISTRY[$identifier]="$module_name"
    MODULE_METADATA[$identifier]="$metadata"

    return 0
}

# Get a module by identifier
# Usage: get_module <identifier>
# Exit code: 0 on success, 1 if not found
get_module() {
    local identifier="$1"

    if [[ -z "$identifier" ]]; then
        echo "Error: Module identifier cannot be empty" >&2
        return 1
    fi

    if [[ -z "${MODULE_REGISTRY[$identifier]}" ]]; then
        echo "Error: Module '$identifier' not found" >&2
        return 1
    fi

    echo "${MODULE_REGISTRY[$identifier]}"
    return 0
}

# Get module metadata by identifier
# Usage: get_module_metadata <identifier>
# Exit code: 0 on success, 1 if not found
get_module_metadata() {
    local identifier="$1"

    if [[ -z "$identifier" ]]; then
        echo "Error: Module identifier cannot be empty" >&2
        return 1
    fi

    if [[ -z "${MODULE_METADATA[$identifier]}" ]]; then
        echo "Error: Module '$identifier' not found" >&2
        return 1
    fi

    echo "${MODULE_METADATA[$identifier]}"
    return 0
}

# Get all registered module identifiers
# Usage: get_all_modules
# Returns: List of module identifiers, one per line
get_all_modules() {
    # Ensure arrays are initialized
    if [[ -z "${MODULE_REGISTRY[*]}" ]]; then
        return 0
    fi

    local identifier
    for identifier in "${!MODULE_REGISTRY[@]}"; do
        echo "$identifier"
    done
}

# Get modules by capability
# Usage: get_modules_by_capability <capability>
# Returns: List of module identifiers that have the specified capability, one per line
get_modules_by_capability() {
    local capability="$1"

    if [[ -z "$capability" ]]; then
        return 0
    fi

    local identifier
    local modules=""
    for identifier in "${!MODULE_REGISTRY[@]}"; do
        # Get module metadata
        local metadata="${MODULE_METADATA[$identifier]}"
        
        if [[ -z "$metadata" ]]; then
            continue
        fi

        # Check if metadata contains the capability
        # Capabilities are stored as capabilities_0=..., capabilities_1=..., etc.
        # Use grep to check for capability in metadata
        if echo "$metadata" | grep -q "^capabilities_[0-9]*=${capability}$"; then
            if [[ -z "$modules" ]]; then
                modules="$identifier"
            else
                modules="${modules}"$'\n'"${identifier}"
            fi
        fi
    done

    if [[ -n "$modules" ]]; then
        echo "$modules"
    fi

    return 0
}

# Get all registered capabilities
# Usage: get_capabilities
# Returns: List of all capabilities from all modules, one per line (deduplicated)
get_capabilities() {
    local identifier
    local all_capabilities=""
    
    for identifier in "${!MODULE_REGISTRY[@]}"; do
        # Get module metadata
        local metadata="${MODULE_METADATA[$identifier]}"
        
        if [[ -z "$metadata" ]]; then
            continue
        fi

        # Extract capabilities from metadata using grep
        # Capabilities are stored as capabilities_0=..., capabilities_1=..., etc.
        local capabilities
        capabilities=$(echo "$metadata" | grep --color=never "^capabilities_[0-9]*=" | sed 's/^capabilities_[0-9]*=//')
        
        # Add capabilities to the list
        if [[ -n "$capabilities" ]]; then
            if [[ -z "$all_capabilities" ]]; then
                all_capabilities="$capabilities"
            else
                all_capabilities="${all_capabilities}"$'\n'"${capabilities}"
            fi
        fi
    done

    # Deduplicate and sort capabilities
    if [[ -n "$all_capabilities" ]]; then
        echo "$all_capabilities" | sort -u
    fi

    return 0
}

# Get modules by type
# Usage: get_modules_by_type <module_type>
# Returns: List of module identifiers of the specified type, one per line
# Module types: language, framework, project
get_modules_by_type() {
    local module_type="$1"
    local identifier
    local modules=""
    
    if [[ -z "$module_type" ]]; then
        return 0
    fi
    
    for identifier in "${!MODULE_REGISTRY[@]}"; do
        # Get module metadata
        local metadata="${MODULE_METADATA[$identifier]}"
        
        if [[ -z "$metadata" ]]; then
            continue
        fi

        # Extract module_type from metadata
        local metadata_type
        metadata_type=$(echo "$metadata" | grep --color=never "^module_type=" | cut -d'=' -f2 || echo "")
        
        # Match module type (case-sensitive)
        if [[ "$metadata_type" == "$module_type" ]]; then
            if [[ -z "$modules" ]]; then
                modules="$identifier"
            else
                modules="${modules}"$'\n'"${identifier}"
            fi
        fi
    done

    if [[ -n "$modules" ]]; then
        echo "$modules"
    fi

    return 0
}

# Get language modules (convenience method)
# Usage: get_language_modules
# Returns: List of language module identifiers, one per line
get_language_modules() {
    get_modules_by_type "language"
    return 0
}

# Get framework modules (convenience method)
# Usage: get_framework_modules
# Returns: List of framework module identifiers, one per line
get_framework_modules() {
    get_modules_by_type "framework"
    return 0
}

# Get project modules (convenience method)
# Usage: get_project_modules
# Returns: List of project module identifiers, one per line
get_project_modules() {
    get_modules_by_type "project"
    return 0
}

# Get tool modules (convenience method)
# Usage: get_tool_modules
# Returns: List of tool module identifiers, one per line
get_tool_modules() {
    get_modules_by_type "tool"
    return 0
}


# End of: src/mod_registry.sh

# Included from: src/platform_detector.sh
#!/usr/bin/env bash

# Suitey Platform Detector
# Identifies which programming languages/frameworks are present in a project
# Uses Suitey Modules Registry to coordinate language-specific detection
# No external dependencies

# Source data access functions if available (for parsing flat data)
if [[ -f "src/data_access.sh" ]]; then
    source "src/data_access.sh" 2>/dev/null || true
fi

# Check container environment readiness
# Usage: check_container_environment
# Returns: Container environment status as flat data
# Behavior: Verifies Docker daemon accessibility, basic container operations, and network connectivity
check_container_environment() {
    local results=""
    local warnings=""

    # Check Docker command availability
    local docker_command_available="false"
    if command -v docker >/dev/null 2>&1; then
        docker_command_available="true"
    fi
    results="${results}docker_command_available=${docker_command_available}"$'\n'

    # Check Docker daemon accessibility (only if command is available)
    local docker_daemon_available="false"
    if [[ "$docker_command_available" == "true" ]]; then
        # Check if docker daemon is accessible
        if docker info >/dev/null 2>&1; then
            docker_daemon_available="true"
        else
            warnings="${warnings}Docker daemon is not running or accessible. Suitey requires Docker for test execution."$'\n'
        fi
    else
        warnings="${warnings}Docker command not found. Install Docker to enable test execution in containers."$'\n'
    fi
    results="${results}docker_daemon_available=${docker_daemon_available}"$'\n'

    # Check basic container operations (only if daemon is available)
    local container_operations="false"
    if [[ "$docker_daemon_available" == "true" ]]; then
        # Try to run a simple container operation
        if docker run --rm alpine:latest echo "test" >/dev/null 2>&1; then
            container_operations="true"
        else
            warnings="${warnings}Cannot execute basic container operations. Check Docker permissions and configuration."$'\n'
        fi
    fi
    results="${results}container_operations=${container_operations}"$'\n'

    # Check network connectivity for image pulls (only if daemon is available)
    local network_access="false"
    if [[ "$docker_daemon_available" == "true" ]]; then
        # Try to pull a small image to test network access
        if docker pull alpine:latest >/dev/null 2>&1; then
            network_access="true"
            # Clean up the pulled image
            docker rmi alpine:latest >/dev/null 2>&1 || true
        else
            warnings="${warnings}Cannot pull Docker images. Check network connectivity and Docker registry access."$'\n'
        fi
    fi
    results="${results}network_access=${network_access}"$'\n'

    # Provide backward compatibility aliases
    results="${results}docker_available=${docker_daemon_available}"$'\n'

    # Add warnings to results
    if [[ -n "$warnings" ]]; then
        # Convert warnings to flat data format
        local warning_count=0
        while IFS= read -r warning_line || [[ -n "$warning_line" ]]; do
            if [[ -n "$warning_line" ]]; then
                results="${results}docker_warnings_${warning_count}=${warning_line}"$'\n'
                ((warning_count++))
            fi
        done <<< "$warnings"
        results="${results}docker_warnings_count=${warning_count}"$'\n'
    else
        results="${results}docker_warnings_count=0"$'\n'
    fi

    echo "$results"
}

# Detect platforms in a project
# Usage: detect_platforms <project_root>
# Returns: Detection results as flat data
# Behavior: Uses Modules Registry to get all modules, calls each module's detect() method, aggregates results
detect_platforms() {
    local project_root="$1"

    # Validate input
    if [[ -z "$project_root" ]]; then
        echo "platforms_count=0"
        return 0
    fi

    # Get all registered modules
    local modules
    modules=$(get_all_modules 2>/dev/null || echo "")

    if [[ -z "$modules" ]]; then
        echo "platforms_count=0"
        return 0
    fi

    # Track detected platforms
    local platforms_count=0
    local platform_index=0
    local results=""

    # Check container environment readiness
    local container_env_status
    container_env_status=$(check_container_environment 2>/dev/null || echo "")
    if [[ -n "$container_env_status" ]]; then
        results="${results}${container_env_status}"
    fi

    # Process each module
    while IFS= read -r module_id || [[ -n "$module_id" ]]; do
        # Determine module file path based on module_id
        # Module IDs follow pattern: {language}-module or {framework}-module
        # Module files are at: mod/languages/{language}/mod.sh or mod/frameworks/{framework}/mod.sh
        local module_file=""

        # Try language modules first
        if [[ "$module_id" == *"-module" ]]; then
            local language="${module_id%-module}"
            module_file="mod/languages/${language}/mod.sh"
        fi

        # If not a language module, try framework modules
        if [[ ! -f "$module_file" ]] && [[ "$module_id" == *"-module" ]]; then
            local framework="${module_id%-module}"
            module_file="mod/frameworks/${framework}/mod.sh"
        fi

        # If not a framework module, try tool modules
        if [[ ! -f "$module_file" ]] && [[ "$module_id" == *"-module" ]]; then
            local tool="${module_id%-module}"
            module_file="mod/tools/${tool}/mod.sh"
        fi

        # If not found, skip
        if [[ ! -f "$module_file" ]]; then
            continue
        fi

        # Clean up any existing module functions to avoid conflicts
        for method in detect check_binaries discover_test_suites detect_build_requirements get_build_steps execute_test_suite parse_test_results get_metadata; do
            unset -f "$method" 2>/dev/null || true
        done

        # Source the module
        source "$module_file" 2>/dev/null || continue

        # Call module's detect() method
        local detection_result
        detection_result=$(detect "$project_root" 2>/dev/null || echo "")

        if [[ -z "$detection_result" ]]; then
            continue
        fi

        # Check if platform was detected
        local detected
        if declare -f data_get >/dev/null 2>&1; then
            detected=$(data_get "$detection_result" "detected" || echo "false")
        else
            detected=$(echo "$detection_result" | grep "^detected=" | cut -d'=' -f2 || echo "false")
        fi

        if [[ "$detected" == "true" ]]; then
            # Platform detected - extract language and framework from detection result
            local language
            local framework
            local confidence

            if declare -f data_get >/dev/null 2>&1; then
                language=$(data_get "$detection_result" "language" || echo "")
                framework=$(data_get "$detection_result" "frameworks_0" || echo "")
                confidence=$(data_get "$detection_result" "confidence" || echo "low")
            else
                language=$(echo "$detection_result" | grep "^language=" | cut -d'=' -f2 || echo "")
                framework=$(echo "$detection_result" | grep "^frameworks_0=" | cut -d'=' -f2 || echo "")
                confidence=$(echo "$detection_result" | grep "^confidence=" | cut -d'=' -f2 || echo "low")
            fi

            # Validate required metadata for detected platforms
            if [[ -z "$language" ]]; then
                echo "Warning: Module '$module_id' detected platform but did not specify language. Skipping platform." >&2
                continue
            fi

            # Add platform to results
            if [[ -n "$results" ]]; then
                results="${results}"$'\n'"platforms_${platform_index}_language=${language}"
            else
                results="platforms_${platform_index}_language=${language}"
            fi

            if [[ -n "$framework" ]]; then
                results="${results}"$'\n'"platforms_${platform_index}_framework=${framework}"
            fi

            results="${results}"$'\n'"platforms_${platform_index}_confidence=${confidence}"
            results="${results}"$'\n'"platforms_${platform_index}_module_id=${module_id}"

            # Add module metadata from get_metadata()
            local module_metadata
            if declare -f get_metadata >/dev/null 2>&1; then
                module_metadata=$(get_metadata 2>/dev/null || echo "")
                if [[ -n "$module_metadata" ]]; then
                    # Parse and prefix each metadata line with platform index
                    while IFS= read -r metadata_line || [[ -n "$metadata_line" ]]; do
                        if [[ -n "$metadata_line" ]]; then
                            results="${results}"$'\n'"platforms_${platform_index}_${metadata_line}"
                        fi
                    done <<< "$module_metadata"
                fi
            fi

            # Add detection indicators
            local indicators_count
            if declare -f data_array_count >/dev/null 2>&1; then
                indicators_count=$(data_array_count "$detection_result" "indicators" || echo "0")
            else
                indicators_count=$(echo "$detection_result" | grep "^indicators_count=" | cut -d'=' -f2 || echo "0")
            fi
            results="${results}"$'\n'"platforms_${platform_index}_indicators_count=${indicators_count}"

            # Add individual indicators
            local i=0
            while [[ $i -lt "$indicators_count" ]]; do
                local indicator
                if declare -f data_get_array >/dev/null 2>&1; then
                    indicator=$(data_get_array "$detection_result" "indicators" "$i" || echo "")
                else
                    indicator=$(echo "$detection_result" | grep "^indicators_${i}=" | cut -d'=' -f2 || echo "")
                fi
                if [[ -n "$indicator" ]]; then
                    results="${results}"$'\n'"platforms_${platform_index}_indicators_${i}=${indicator}"
                fi
                i=$((i + 1))
            done


            platforms_count=$((platforms_count + 1))
            platform_index=$((platform_index + 1))
        fi
    done <<< "$modules"

    # Output results
    echo "platforms_count=${platforms_count}"
    if [[ -n "$results" ]]; then
        echo "$results"
    fi

    return 0
}

# End of: src/platform_detector.sh

# Included from: src/project_scanner.sh
#!/usr/bin/env bash

# Project Scanner (Orchestrator)
# Coordinates Platform Detection, Test Suite Detection, and Build System Detection
# Provides unified interface for project analysis

# Source required dependencies
source "src/platform_detector.sh" 2>/dev/null || true
source "src/test_suite_detector.sh" 2>/dev/null || true
source "src/build_system_detector.sh" 2>/dev/null || true
source "src/data_access.sh" 2>/dev/null || true

# Scan project and detect all aspects
# Usage: scan_project <project_root>
# Returns: Unified project scan results in flat data format
# Behavior: Orchestrates all detection phases in correct order
scan_project() {
    local project_root="$1"

    # Validate input
    if [[ -z "$project_root" ]]; then
        echo "Error: Project root is required" >&2
        echo "scan_result=error"
        echo "error_message=Project root is required"
        return 1
    fi

    if [[ ! -d "$project_root" ]]; then
        echo "Error: Project root directory does not exist: $project_root" >&2
        echo "scan_result=error"
        echo "error_message=Project root directory does not exist"
        return 1
    fi

    # Initialize result data
    local result=""
    local scan_success=true

    # Phase 1: Platform Detection
    result=$(data_set "$result" "scan_result" "success")
    result=$(data_set "$result" "project_root" "$project_root")

    echo "Starting platform detection for: $project_root" >&2

    local platform_data
    if platform_data=$(detect_platforms "$project_root" 2>&1); then
        result=$(data_set "$result" "platform_detection_status" "success")
        echo "Platform detection completed successfully" >&2
    else
        result=$(data_set "$result" "platform_detection_status" "failed")
        result=$(data_set "$result" "platform_detection_error" "$platform_data")
        result=$(data_set "$result" "scan_result" "partial")
        scan_success=false
        echo "Platform detection failed: $platform_data" >&2
        # Continue with empty platform data for other phases
        platform_data="platforms_count=0"
    fi

    # Include platform detection results
    result="${result}${platform_data}"$'\n'

    # Phase 2: Test Suite Detection (depends on platform detection)
    echo "Starting test suite detection" >&2

    local suite_data
    if suite_data=$(discover_test_suites "$platform_data" 2>&1); then
        result=$(data_set "$result" "test_suite_detection_status" "success")
        echo "Test suite detection completed successfully" >&2
    else
        result=$(data_set "$result" "test_suite_detection_status" "failed")
        result=$(data_set "$result" "test_suite_detection_error" "$suite_data")
        result=$(data_set "$result" "scan_result" "partial")
        scan_success=false
        echo "Test suite detection failed: $suite_data" >&2
        # Continue with empty suite data
        suite_data="suites_count=0"
    fi

    # Include test suite detection results
    result="${result}${suite_data}"$'\n'

    # Phase 3: Build System Detection (depends on platform detection)
    echo "Starting build system detection" >&2

    local build_data
    if build_data=$(detect_build_requirements "$platform_data" 2>&1); then
        result=$(data_set "$result" "build_system_detection_status" "success")
        echo "Build system detection completed successfully" >&2
    else
        result=$(data_set "$result" "build_system_detection_status" "failed")
        result=$(data_set "$result" "build_system_detection_error" "$build_data")
        result=$(data_set "$result" "scan_result" "partial")
        scan_success=false
        echo "Build system detection failed: $build_data" >&2
        # Continue with safe defaults
        build_data="requires_build=false"$'\n'"build_commands_count=0"$'\n'"build_dependencies_count=0"$'\n'"build_artifacts_count=0"
    fi

    # Include build system detection results
    result="${result}${build_data}"$'\n'

    # Phase 4: Build Steps Detection (depends on build requirements)
    echo "Starting build steps detection" >&2

    local build_steps_data
    if build_steps_data=$(get_build_steps "$platform_data" "$build_data" 2>&1); then
        result=$(data_set "$result" "build_steps_detection_status" "success")
        echo "Build steps detection completed successfully" >&2
    else
        result=$(data_set "$result" "build_steps_detection_status" "failed")
        result=$(data_set "$result" "build_steps_detection_error" "$build_steps_data")
        result=$(data_set "$result" "scan_result" "partial")
        scan_success=false
        echo "Build steps detection failed: $build_steps_data" >&2
        # Continue with empty build steps
        build_steps_data="build_steps_count=0"
    fi

    # Include build steps detection results
    result="${result}${build_steps_data}"$'\n'

    # Phase 5: Build Dependency Analysis (depends on build steps)
    echo "Starting build dependency analysis" >&2

    local dependency_data
    if dependency_data=$(analyze_build_dependencies "$build_steps_data" 2>&1); then
        result=$(data_set "$result" "build_dependency_analysis_status" "success")
        echo "Build dependency analysis completed successfully" >&2
    else
        result=$(data_set "$result" "build_dependency_analysis_status" "failed")
        result=$(data_set "$result" "build_dependency_analysis_error" "$dependency_data")
        result=$(data_set "$result" "scan_result" "partial")
        scan_success=false
        echo "Build dependency analysis failed: $dependency_data" >&2
        # Continue with safe defaults
        dependency_data="execution_order_count=0"$'\n'"parallel_groups_count=0"$'\n'"dependency_graph_count=0"
    fi

    # Include build dependency analysis results
    result="${result}${dependency_data}"$'\n'

    # Final status
    if [[ "$scan_success" == true ]]; then
        result=$(data_set "$result" "scan_result" "success")
        echo "Project scan completed successfully" >&2
    else
        echo "Project scan completed with partial failures" >&2
    fi

    echo "$result"
    return 0
}

# End of: src/project_scanner.sh

# Included from: src/suite_grouping.sh
#!/usr/bin/env bash

# Suite Grouping Functions
# Implements adaptive detection strategies for grouping test files into suites
# No external dependencies

# Source required dependencies
source "src/data_access.sh" 2>/dev/null || true

# Check if configuration file exists
# Usage: has_configuration_file <project_root>
# Returns: 0 if config file exists, 1 otherwise
# Outputs: "suitey.toml" or ".suiteyrc" if found
has_configuration_file() {
    local project_root="$1"
    
    if [[ -z "$project_root" ]] || [[ ! -d "$project_root" ]]; then
        return 1
    fi
    
    if [[ -f "$project_root/suitey.toml" ]]; then
        echo "suitey.toml"
        return 0
    elif [[ -f "$project_root/.suiteyrc" ]]; then
        echo ".suiteyrc"
        return 0
    fi
    
    return 1
}

# Parse TOML configuration file (simplified parser for suitey.toml)
# Usage: parse_toml_config <config_file>
# Returns: Suite definitions in flat data format
# Note: This is a simplified TOML parser that handles only the subset needed for Suitey
parse_toml_config() {
    local config_file="$1"
    
    if [[ -z "$config_file" ]] || [[ ! -f "$config_file" ]]; then
        return 1
    fi
    
    local suites_count=0
    local suite_index=0
    local in_suite=false
    local current_suite_name=""
    local current_suite_files=()
    local result=""
    
    while IFS= read -r line || [[ -n "$line" ]]; do
        # Remove leading/trailing whitespace
        line="${line#"${line%%[![:space:]]*}"}"
        line="${line%"${line##*[![:space:]]}"}"
        
        # Skip empty lines and comments
        if [[ -z "$line" ]] || [[ "$line" =~ ^[[:space:]]*# ]]; then
            continue
        fi
        
        # Check for suite table array start: [[suites]]
        if [[ "$line" =~ ^\[\[suites\]\] ]]; then
            # Save previous suite if we were in one
            if [[ "$in_suite" == true ]] && [[ -n "$current_suite_name" ]] && [[ ${#current_suite_files[@]} -gt 0 ]]; then
                result=$(data_set "$result" "suites_${suite_index}_name" "$current_suite_name")
                local file_idx=0
                for file_pattern in "${current_suite_files[@]}"; do
                    result=$(data_set "$result" "suites_${suite_index}_files_${file_idx}" "$file_pattern")
                    ((file_idx++))
                done
                result=$(data_set "$result" "suites_${suite_index}_files_count" "$file_idx")
                ((suite_index++))
                ((suites_count++))
            fi
            
            # Start new suite
            in_suite=true
            current_suite_name=""
            current_suite_files=()
            continue
        fi
        
        # If we're in a suite, parse fields
        if [[ "$in_suite" == true ]]; then
            # Parse name = "value"
            if [[ "$line" =~ ^name[[:space:]]*=[[:space:]]*\"(.*)\" ]]; then
                current_suite_name="${BASH_REMATCH[1]}"
            elif [[ "$line" =~ ^name[[:space:]]*=[[:space:]]*\'([^\']*)\' ]]; then
                current_suite_name="${BASH_REMATCH[1]}"
            elif [[ "$line" =~ ^name[[:space:]]*=[[:space:]]*([^[:space:]]+) ]]; then
                current_suite_name="${BASH_REMATCH[1]}"
            fi
            
            # Parse files = ["pattern1", "pattern2"]
            if [[ "$line" =~ ^files[[:space:]]*=[[:space:]]*\[ ]]; then
                # Multi-line array - collect until closing bracket
                local array_content="${line#*\[}"
                array_content="${array_content%\]}"
                
                # Extract quoted strings
                while [[ "$array_content" =~ \"([^\"]+)\" ]]; do
                    current_suite_files+=("${BASH_REMATCH[1]}")
                    array_content="${array_content#*\"${BASH_REMATCH[1]}\"}"
                    array_content="${array_content#*,}"
                    array_content="${array_content#"${array_content%%[![:space:]]*}"}"
                done
            fi
            
            # Check if we've hit another section (starts with [)
            if [[ "$line" =~ ^\[ ]]; then
                # Save current suite
                if [[ -n "$current_suite_name" ]] && [[ ${#current_suite_files[@]} -gt 0 ]]; then
                    result=$(data_set "$result" "suites_${suite_index}_name" "$current_suite_name")
                    local file_idx=0
                    for file_pattern in "${current_suite_files[@]}"; do
                        result=$(data_set "$result" "suites_${suite_index}_files_${file_idx}" "$file_pattern")
                        ((file_idx++))
                    done
                    result=$(data_set "$result" "suites_${suite_index}_files_count" "$file_idx")
                    ((suite_index++))
                    ((suites_count++))
                fi
                in_suite=false
                current_suite_name=""
                current_suite_files=()
            fi
        fi
    done < "$config_file"
    
    # Save last suite if we were in one
    if [[ "$in_suite" == true ]] && [[ -n "$current_suite_name" ]] && [[ ${#current_suite_files[@]} -gt 0 ]]; then
        result=$(data_set "$result" "suites_${suite_index}_name" "$current_suite_name")
        local file_idx=0
        for file_pattern in "${current_suite_files[@]}"; do
            result=$(data_set "$result" "suites_${suite_index}_files_${file_idx}" "$file_pattern")
            ((file_idx++))
        done
        result=$(data_set "$result" "suites_${suite_index}_files_count" "$file_idx")
        ((suites_count++))
    fi
    
    # Set suites count
    result=$(data_set "$result" "suites_count" "$suites_count")
    
    echo "$result"
    return 0
}

# Check if directory matches conventional test suite names
# Usage: is_conventional_directory <directory_name>
# Returns: 0 if conventional, 1 otherwise
# Outputs: normalized suite name if conventional
is_conventional_directory() {
    local dir_name="$1"
    local normalized_name
    
    case "$dir_name" in
        unit|units)
            echo "unit"
            return 0
            ;;
        integration|integrations)
            echo "integration"
            return 0
            ;;
        e2e|end-to-end|end_to_end)
            echo "e2e"
            return 0
            ;;
        performance|perf)
            echo "performance"
            return 0
            ;;
        *)
            return 1
            ;;
    esac
}

# Group test files using convention-based strategy
# Usage: group_by_convention <project_root> <test_files>
# Returns: Grouped suites in flat data format
group_by_convention() {
    local project_root="$1"
    local test_files="$2"
    
    if [[ -z "$test_files" ]]; then
        echo "suites_count=0"
        return 0
    fi
    
    local suites_count=0
    local suite_index=0
    local result=""
    
    # Group files by their parent directory if it's conventional
    declare -A suite_files
    
    while IFS= read -r file || [[ -n "$file" ]]; do
        if [[ -z "$file" ]]; then
            continue
        fi
        
        # Get directory name
        local file_dir
        file_dir=$(dirname "$file")
        file_dir="${file_dir#$project_root/}"
        
        # Check each level of the path for conventional names
        local suite_name=""
        local path_parts
        IFS='/' read -ra path_parts <<< "$file_dir"
        
        for part in "${path_parts[@]}"; do
            if is_conventional_directory "$part" >/dev/null 2>&1; then
                suite_name=$(is_conventional_directory "$part")
                break
            fi
        done
        
        # If no conventional name found, use directory basename
        if [[ -z "$suite_name" ]]; then
            suite_name=$(basename "$file_dir")
            if [[ -z "$suite_name" ]] || [[ "$suite_name" == "." ]]; then
                suite_name="default"
            fi
        fi
        
        # Add file to suite
        if [[ -z "${suite_files[$suite_name]}" ]]; then
            suite_files[$suite_name]="$file"
        else
            suite_files[$suite_name]="${suite_files[$suite_name]}"$'\n'"$file"
        fi
    done <<< "$test_files"
    
    # Convert to flat data format
    for suite_name in "${!suite_files[@]}"; do
        local files_list="${suite_files[$suite_name]}"
        local file_count=0
        local file_idx=0
        
        result=$(data_set "$result" "suites_${suite_index}_name" "$suite_name")
        
        while IFS= read -r file || [[ -n "$file" ]]; do
            if [[ -n "$file" ]]; then
                result=$(data_set "$result" "suites_${suite_index}_files_${file_idx}" "$file")
                ((file_idx++))
                ((file_count++))
            fi
        done <<< "$files_list"
        
        result=$(data_set "$result" "suites_${suite_index}_files_count" "$file_count")
        ((suite_index++))
        ((suites_count++))
    done
    
    result=$(data_set "$result" "suites_count" "$suites_count")
    echo "$result"
    return 0
}

# Group test files by subdirectory structure (preserves user organization)
# Usage: group_by_subdirectory <project_root> <test_files>
# Returns: Grouped suites in flat data format
group_by_subdirectory() {
    local project_root="$1"
    local test_files="$2"
    
    if [[ -z "$test_files" ]]; then
        echo "suites_count=0"
        return 0
    fi
    
    local suites_count=0
    local suite_index=0
    local result=""
    declare -A suite_files
    
    while IFS= read -r file || [[ -n "$file" ]]; do
        if [[ -z "$file" ]]; then
            continue
        fi
        
        # Get relative directory path
        local file_dir
        file_dir=$(dirname "$file")
        file_dir="${file_dir#$project_root/}"
        
        # Use the directory path as suite name (normalize)
        local suite_name="$file_dir"
        if [[ -z "$suite_name" ]] || [[ "$suite_name" == "." ]]; then
            suite_name="root"
        fi
        
        # Normalize path separators
        suite_name="${suite_name//\//_}"
        
        # Add file to suite
        if [[ -z "${suite_files[$suite_name]}" ]]; then
            suite_files[$suite_name]="$file"
        else
            suite_files[$suite_name]="${suite_files[$suite_name]}"$'\n'"$file"
        fi
    done <<< "$test_files"
    
    # Convert to flat data format
    for suite_name in "${!suite_files[@]}"; do
        local files_list="${suite_files[$suite_name]}"
        local file_count=0
        local file_idx=0
        
        result=$(data_set "$result" "suites_${suite_index}_name" "$suite_name")
        
        while IFS= read -r file || [[ -n "$file" ]]; do
            if [[ -n "$file" ]]; then
                result=$(data_set "$result" "suites_${suite_index}_files_${file_idx}" "$file")
                ((file_idx++))
                ((file_count++))
            fi
        done <<< "$files_list"
        
        result=$(data_set "$result" "suites_${suite_index}_files_count" "$file_count")
        ((suite_index++))
        ((suites_count++))
    done
    
    result=$(data_set "$result" "suites_count" "$suites_count")
    echo "$result"
    return 0
}

# Group test files by directory (all files in a directory = one suite)
# Usage: group_by_directory <project_root> <test_files>
# Returns: Grouped suites in flat data format
group_by_directory() {
    local project_root="$1"
    local test_files="$2"
    
    if [[ -z "$test_files" ]]; then
        echo "suites_count=0"
        return 0
    fi
    
    local suites_count=0
    local suite_index=0
    local result=""
    declare -A suite_files
    
    while IFS= read -r file || [[ -n "$file" ]]; do
        if [[ -z "$file" ]]; then
            continue
        fi
        
        # Get directory basename as suite name
        local file_dir
        file_dir=$(dirname "$file")
        local suite_name
        suite_name=$(basename "$file_dir")
        
        if [[ -z "$suite_name" ]] || [[ "$suite_name" == "." ]]; then
            suite_name="root"
        fi
        
        # Add file to suite
        if [[ -z "${suite_files[$suite_name]}" ]]; then
            suite_files[$suite_name]="$file"
        else
            suite_files[$suite_name]="${suite_files[$suite_name]}"$'\n'"$file"
        fi
    done <<< "$test_files"
    
    # Convert to flat data format
    for suite_name in "${!suite_files[@]}"; do
        local files_list="${suite_files[$suite_name]}"
        local file_count=0
        local file_idx=0
        
        result=$(data_set "$result" "suites_${suite_index}_name" "$suite_name")
        
        while IFS= read -r file || [[ -n "$file" ]]; do
            if [[ -n "$file" ]]; then
                result=$(data_set "$result" "suites_${suite_index}_files_${file_idx}" "$file")
                ((file_idx++))
                ((file_count++))
            fi
        done <<< "$files_list"
        
        result=$(data_set "$result" "suites_${suite_index}_files_count" "$file_count")
        ((suite_index++))
        ((suites_count++))
    done
    
    result=$(data_set "$result" "suites_count" "$suites_count")
    echo "$result"
    return 0
}

# Group test files by file (each file = one suite)
# Usage: group_by_file <test_files>
# Returns: Grouped suites in flat data format
group_by_file() {
    local test_files="$1"
    
    if [[ -z "$test_files" ]]; then
        echo "suites_count=0"
        return 0
    fi
    
    local suites_count=0
    local suite_index=0
    local result=""
    
    while IFS= read -r file || [[ -n "$file" ]]; do
        if [[ -z "$file" ]]; then
            continue
        fi
        
        # Use filename (without extension) as suite name
        local suite_name
        suite_name=$(basename "$file")
        suite_name="${suite_name%.*}"
        
        if [[ -z "$suite_name" ]]; then
            suite_name="test_${suite_index}"
        fi
        
        result=$(data_set "$result" "suites_${suite_index}_name" "$suite_name")
        result=$(data_set "$result" "suites_${suite_index}_files_0" "$file")
        result=$(data_set "$result" "suites_${suite_index}_files_count" "1")
        ((suite_index++))
        ((suites_count++))
    done <<< "$test_files"
    
    result=$(data_set "$result" "suites_count" "$suites_count")
    echo "$result"
    return 0
}

# Apply adaptive suite grouping strategy
# Usage: apply_adaptive_grouping <project_root> <test_files>
# Returns: Grouped suites in flat data format
apply_adaptive_grouping() {
    local project_root="$1"
    local test_files="$2"
    
    if [[ -z "$test_files" ]]; then
        echo "suites_count=0"
        return 0
    fi
    
    # Strategy 1: Configuration-Driven (highest priority)
    local config_file
    config_file=$(has_configuration_file "$project_root")
    if [[ $? -eq 0 ]]; then
        local config_suites
        config_suites=$(parse_toml_config "$project_root/$config_file" 2>/dev/null)
        if [[ $? -eq 0 ]] && [[ -n "$config_suites" ]]; then
            local config_suites_count
            config_suites_count=$(data_get "$config_suites" "suites_count")
            if [[ -n "$config_suites_count" ]] && [[ "$config_suites_count" -gt 0 ]]; then
                echo "$config_suites"
                return 0
            fi
        fi
    fi
    
    # Strategy 2: Convention-Based
    local convention_result
    convention_result=$(group_by_convention "$project_root" "$test_files")
    local convention_count
    convention_count=$(data_get "$convention_result" "suites_count")
    
    # Check if we found conventional directories
    if [[ -n "$convention_count" ]] && [[ "$convention_count" -gt 0 ]]; then
        # Verify we actually grouped by convention (not just default)
        local has_conventional=false
        local i=0
        while [[ $i -lt "$convention_count" ]]; do
            local suite_name
            suite_name=$(data_get "$convention_result" "suites_${i}_name")
            if is_conventional_directory "$suite_name" >/dev/null 2>&1; then
                has_conventional=true
                break
            fi
            ((i++))
        done
        
        if [[ "$has_conventional" == true ]]; then
            echo "$convention_result"
            return 0
        fi
    fi
    
    # Strategy 3: Subdirectory-Aware
    # Check if files are organized in subdirectories
    local has_subdirs=false
    while IFS= read -r file || [[ -n "$file" ]]; do
        if [[ -n "$file" ]]; then
            local file_dir
            file_dir=$(dirname "$file")
            file_dir="${file_dir#$project_root/}"
            if [[ "$file_dir" != "." ]] && [[ "$file_dir" != "$(basename "$file")" ]]; then
                has_subdirs=true
                break
            fi
        fi
    done <<< "$test_files"
    
    if [[ "$has_subdirs" == true ]]; then
        echo "$(group_by_subdirectory "$project_root" "$test_files")"
        return 0
    fi
    
    # Strategy 4: Directory-Based
    local dir_result
    dir_result=$(group_by_directory "$project_root" "$test_files")
    local dir_count
    dir_count=$(data_get "$dir_result" "suites_count")
    
    if [[ -n "$dir_count" ]] && [[ "$dir_count" -gt 0 ]]; then
        echo "$dir_result"
        return 0
    fi
    
    # Strategy 5: File-Level (fallback)
    echo "$(group_by_file "$test_files")"
    return 0
}


# End of: src/suite_grouping.sh

# Included from: src/test_counter.sh
#!/usr/bin/env bash

# Test Counter Functions
# Counts individual tests in test files using platform-specific patterns
# No external dependencies

# Count tests in a BATS file
# Usage: count_bats_tests <file_path>
# Returns: Number of @test annotations found
count_bats_tests() {
    local file_path="$1"
    
    if [[ -z "$file_path" ]] || [[ ! -f "$file_path" ]]; then
        echo "0"
        return 0
    fi
    
    # Count @test annotations (excluding comments and strings)
    # Pattern: @test followed by optional whitespace and quoted string
    local count=0
    
    while IFS= read -r line || [[ -n "$line" ]]; do
        # Remove leading/trailing whitespace
        line="${line#"${line%%[![:space:]]*}"}"
        line="${line%"${line##*[![:space:]]}"}"
        
        # Skip empty lines and comments
        if [[ -z "$line" ]] || [[ "$line" =~ ^[[:space:]]*# ]]; then
            continue
        fi
        
        # Check for @test annotation
        if [[ "$line" =~ @test ]]; then
            ((count++))
        fi
    done < "$file_path"
    
    echo "$count"
    return 0
}

# Count tests in a Rust file
# Usage: count_rust_tests <file_path>
# Returns: Number of #[test] functions found
count_rust_tests() {
    local file_path="$1"
    
    if [[ -z "$file_path" ]] || [[ ! -f "$file_path" ]]; then
        echo "0"
        return 0
    fi
    
    local count=0
    local in_test_module=false
    local brace_depth=0
    local test_module_started=false
    
    while IFS= read -r line || [[ -n "$line" ]]; do
        # Keep original line for pattern matching (don't trim yet)
        local original_line="$line"
        
        # Remove leading/trailing whitespace for empty check
        local trimmed_line="${line#"${line%%[![:space:]]*}"}"
        trimmed_line="${trimmed_line%"${trimmed_line##*[![:space:]]}"}"
        
        # Skip empty lines
        if [[ -z "$trimmed_line" ]]; then
            continue
        fi
        
        # Track brace depth
        local open_braces="${original_line//[^\{]/}"
        local close_braces="${original_line//[^\}]/}"
        brace_depth=$((brace_depth + ${#open_braces} - ${#close_braces}))
        
        # Check if we're entering a test module
        if echo "$original_line" | grep -q '#\[cfg(test)\]'; then
            in_test_module=true
            test_module_started=false
            brace_depth=0  # Reset depth when entering test module
            continue
        fi
        
        # Check if we've entered the mod block after #[cfg(test)]
        if [[ "$in_test_module" == true ]] && echo "$original_line" | grep -q '^[[:space:]]*mod[[:space:]]'; then
            test_module_started=true
            continue
        fi
        
        # Count #[test] annotations (allow whitespace before #[test])
        # For integration tests (tests/ directory), count all #[test] regardless of module
        # For unit tests (src/ directory), only count if in #[cfg(test)] module
        if echo "$original_line" | grep -q '#\[test\]'; then
            # If file is in tests/ directory, always count
            if [[ "$file_path" =~ /tests/ ]]; then
                ((count++))
            elif [[ "$in_test_module" == true ]] && [[ "$test_module_started" == true ]]; then
                # If in test module and mod block has started, count it
                ((count++))
            fi
        fi
        
        # Check if we're leaving the test module (brace depth back to 0 or negative)
        if [[ "$in_test_module" == true ]] && [[ "$test_module_started" == true ]] && [[ $brace_depth -le 0 ]]; then
            in_test_module=false
            test_module_started=false
        fi
    done < "$file_path"
    
    echo "$count"
    return 0
}

# Count tests in a file based on file extension
# Usage: count_tests_in_file <file_path>
# Returns: Number of tests found
count_tests_in_file() {
    local file_path="$1"
    
    if [[ -z "$file_path" ]] || [[ ! -f "$file_path" ]]; then
        echo "0"
        return 0
    fi
    
    # Determine file type by extension
    local extension="${file_path##*.}"
    
    case "$extension" in
        bats)
            count_bats_tests "$file_path"
            ;;
        rs)
            count_rust_tests "$file_path"
            ;;
        *)
            # Unknown file type, return 0
            echo "0"
            ;;
    esac
}

# Count total tests in multiple files
# Usage: count_tests_in_files <file1> [file2] [file3] ...
# Returns: Total count of tests across all files
count_tests_in_files() {
    local total=0
    
    for file_path in "$@"; do
        if [[ -n "$file_path" ]] && [[ -f "$file_path" ]]; then
            local file_count
            file_count=$(count_tests_in_file "$file_path")
            total=$((total + file_count))
        fi
    done
    
    echo "$total"
    return 0
}

# Count tests for a suite (given suite data in flat format)
# Usage: count_tests_for_suite <suite_data> <suite_index>
# Returns: Total test count for the suite
count_tests_for_suite() {
    local suite_data="$1"
    local suite_index="$2"
    
    if [[ -z "$suite_data" ]] || [[ -z "$suite_index" ]]; then
        echo "0"
        return 0
    fi
    
    # Source data access functions
    source "src/data_access.sh" 2>/dev/null || true
    
    # Get files count for this suite
    local files_count
    if declare -f data_get >/dev/null 2>&1; then
        files_count=$(data_get "$suite_data" "suites_${suite_index}_files_count" || echo "0")
    else
        files_count=$(echo "$suite_data" | grep "^suites_${suite_index}_files_count=" | cut -d'=' -f2 || echo "0")
    fi
    
    if [[ -z "$files_count" ]] || [[ "$files_count" -eq 0 ]]; then
        echo "0"
        return 0
    fi
    
    # Collect all file paths
    local total=0
    local i=0
    while [[ $i -lt "$files_count" ]]; do
        local file_path
        if declare -f data_get >/dev/null 2>&1; then
            file_path=$(data_get "$suite_data" "suites_${suite_index}_files_${i}" || echo "")
        else
            file_path=$(echo "$suite_data" | grep "^suites_${suite_index}_files_${i}=" | cut -d'=' -f2 || echo "")
        fi
        
        if [[ -n "$file_path" ]] && [[ -f "$file_path" ]]; then
            local file_count
            file_count=$(count_tests_in_file "$file_path")
            total=$((total + file_count))
        fi
        
        ((i++))
    done
    
    echo "$total"
    return 0
}


# End of: src/test_counter.sh

# Included from: src/test_suite_detector.sh
#!/usr/bin/env bash

# Test Suite Detector
# This file implements test suite discovery for detected platforms

# Source required dependencies
source "src/data_access.sh" 2>/dev/null || true
source "src/suite_grouping.sh" 2>/dev/null || true
source "src/test_counter.sh" 2>/dev/null || true

# Discover test suites for detected platforms
# Directly loads and calls module discover_test_suites methods based on platform type
# Returns aggregated results in flat data format
discover_test_suites() {
    local platform_data="$1"

    # Initialize result data
    local result="suites_count=0"

    # Parse platform data to get platforms count
    local platforms_count
    platforms_count=$(data_get "$platform_data" "platforms_count")

    if [[ -z "$platforms_count" ]] || [[ "$platforms_count" -eq 0 ]]; then
        echo "$result"
        return 0
    fi

    # Process each detected platform
    local suite_index=0
    local i=0
    while [[ $i -lt "$platforms_count" ]]; do
        local language
        local framework
        local module_type

        language=$(data_get "$platform_data" "platforms_${i}_language")
        framework=$(data_get "$platform_data" "platforms_${i}_framework")
        module_type=$(data_get "$platform_data" "platforms_${i}_module_type")

        # Determine module file path based on platform type
        local module_file=""
        case "$module_type" in
            "language")
                module_file="mod/languages/${language}/mod.sh"
                ;;
            "framework")
                module_file="mod/frameworks/${framework}/mod.sh"
                ;;
            "project")
                # Project modules would be handled differently
                module_file=""
                ;;
        esac

        # If module file exists, load it and call discover_test_suites
        if [[ -n "$module_file" ]] && [[ -f "$module_file" ]]; then
            # Clean up any existing module functions to avoid conflicts
            for method in detect check_binaries discover_test_suites detect_build_requirements get_build_steps execute_test_suite parse_test_results get_metadata; do
                unset -f "$method" 2>/dev/null || true
            done

            # Source the module
            source "$module_file" 2>/dev/null || continue

            # Get the project root from the platform data
            local project_root
            project_root=$(data_get "$platform_data" "project_root" || echo ".")

            # Call the module's discover_test_suites method
            local module_result
            module_result=$(discover_test_suites "$project_root" "$platform_data" 2>/dev/null || echo "suites_count=0")

            # Parse the module result and add to our result
            local module_suites_count
            module_suites_count=$(data_get "$module_result" "suites_count")

            if [[ -n "$module_suites_count" ]] && [[ "$module_suites_count" -gt 0 ]]; then
                # Add each suite from this module to our result
                local j=0
                while [[ $j -lt "$module_suites_count" ]]; do
                    # Copy suite data from module result to our result
                    local suite_prefix="suites_${suite_index}"
                    local module_suite_prefix="suites_${j}"

                    # Get all lines for this suite from module result
                    local suite_lines
                    suite_lines=$(echo "$module_result" | grep "^${module_suite_prefix}_")

                    # Add each line with updated index
                    while IFS= read -r line; do
                        if [[ -n "$line" ]]; then
                            local new_line="${line/${module_suite_prefix}_/${suite_prefix}_}"
                            result=$(data_set "$result" "${new_line%%=*}" "${new_line#*=}")
                        fi
                    done <<< "$suite_lines"

                    # Count tests for this suite
                    local suite_test_count=0
                    local files_count
                    files_count=$(data_get "$result" "suites_${suite_index}_files_count" || echo "0")
                    
                    if [[ -n "$files_count" ]] && [[ "$files_count" -gt 0 ]]; then
                        local k=0
                        while [[ $k -lt "$files_count" ]]; do
                            local test_file
                            test_file=$(data_get "$result" "suites_${suite_index}_files_${k}" || echo "")
                            
                            if [[ -n "$test_file" ]] && [[ -f "$test_file" ]]; then
                                local file_test_count
                                file_test_count=$(count_tests_in_file "$test_file" || echo "0")
                                suite_test_count=$((suite_test_count + file_test_count))
                            fi
                            ((k++))
                        done
                    fi
                    
                    # Add test count to suite data
                    result=$(data_set "$result" "suites_${suite_index}_test_count" "$suite_test_count")

                    ((suite_index++))
                    ((j++))
                done
            fi

            # Clean up module functions after use
            for method in detect check_binaries discover_test_suites detect_build_requirements get_build_steps execute_test_suite parse_test_results get_metadata; do
                unset -f "$method" 2>/dev/null || true
            done
        fi

        ((i++))
    done

    # Update the final suites count
    result=$(data_set "$result" "suites_count" "$suite_index")

    # Apply adaptive suite grouping if we have suites
    if [[ "$suite_index" -gt 0 ]]; then
        # Get project root from platform data
        local project_root
        project_root=$(data_get "$platform_data" "project_root" || echo ".")
        
        # Collect all test files from discovered suites
        local all_test_files=""
        local i=0
        while [[ $i -lt "$suite_index" ]]; do
            local files_count
            files_count=$(data_get "$result" "suites_${i}_files_count")
            
            if [[ -n "$files_count" ]] && [[ "$files_count" -gt 0 ]]; then
                local j=0
                while [[ $j -lt "$files_count" ]]; do
                    local test_file
                    test_file=$(data_get "$result" "suites_${i}_files_${j}")
                    if [[ -n "$test_file" ]]; then
                        if [[ -z "$all_test_files" ]]; then
                            all_test_files="$test_file"
                        else
                            all_test_files="${all_test_files}"$'\n'"$test_file"
                        fi
                    fi
                    ((j++))
                done
            fi
            ((i++))
        done
        
        # Apply adaptive grouping if we have test files
        if [[ -n "$all_test_files" ]]; then
            local grouped_result
            grouped_result=$(apply_adaptive_grouping "$project_root" "$all_test_files" 2>/dev/null)
            
            # If grouping produced results, use them (configuration-driven takes precedence)
            if [[ $? -eq 0 ]] && [[ -n "$grouped_result" ]]; then
                local grouped_count
                grouped_count=$(data_get "$grouped_result" "suites_count")
                
                # Only use grouped result if configuration file exists (highest priority)
                local config_file
                config_file=$(has_configuration_file "$project_root" 2>/dev/null)
                if [[ $? -eq 0 ]]; then
                    result="$grouped_result"
                fi
            fi
        fi
    fi

    echo "$result"
}


# End of: src/test_suite_detector.sh

# Included from: mod/frameworks/bats/mod.sh
#!/usr/bin/env bash

# Suitey BATS Framework Module
# Handles BATS framework for Bash language
# Provides framework-specific test discovery, execution, and parsing for BATS projects
#
# This module works in conjunction with the Bash language module:
# - Language module (mod/languages/bash/mod.sh) detects Bash language presence
# - Framework module (this module) handles BATS-specific operations
# - Framework module has higher priority than language module for framework-specific operations

# Detect if BATS project is present (framework-level detection)
# Usage: detect <project_root>
# Returns: Detection result as flat data
# Behavior: Checks for .bats files (framework-specific indicator)
detect() {
    local project_root="$1"

    # Validate input
    if [[ -z "$project_root" ]] || [[ ! -d "$project_root" ]]; then
        echo "detected=false"
        echo "confidence=low"
        echo "indicators_count=0"
        echo "language=bash"
        echo "frameworks_0=bats"
        return 0
    fi

    # Check for .bats files (primary BATS indicator)
    # Look in common test directories: tests/bats/, test/bats/, tests/, test/
    local bats_files
    bats_files=$(find "$project_root" -maxdepth 3 -name "*.bats" -type f 2>/dev/null | head -1)
    if [[ -n "$bats_files" ]]; then
        echo "detected=true"
        echo "confidence=high"
        echo "indicators_0=bats_test_files"
        echo "indicators_count=1"
        echo "language=bash"
        echo "frameworks_0=bats"
        return 0
    fi

    # Check for BATS test directory structure (secondary indicator)
    if [[ -d "$project_root/tests/bats" ]] || [[ -d "$project_root/test/bats" ]]; then
        echo "detected=true"
        echo "confidence=medium"
        echo "indicators_0=bats_test_directory"
        echo "indicators_count=1"
        echo "language=bash"
        echo "frameworks_0=bats"
        return 0
    fi

    # Not detected
    echo "detected=false"
    echo "confidence=low"
    echo "indicators_count=0"
    echo "language=bash"
    echo "frameworks_0=bats"
    return 0
}

# Check if required binaries are available
# Usage: check_binaries <project_root>
# Returns: Binary status as flat data
# Behavior: Checks for bats binary in PATH and reports version if available
check_binaries() {
    local project_root="$1"

    # Check for bats binary in PATH
    if command -v bats >/dev/null 2>&1; then
        local bats_version
        bats_version=$(bats --version 2>/dev/null | head -1 || echo "unknown")
        # Remove "bats " prefix if present
        bats_version="${bats_version#bats }"
        echo "available=true"
        echo "binaries_0=bats"
        echo "binaries_count=1"
        echo "versions_bats=$bats_version"
        echo "container_check=false"
    else
        echo "available=false"
        echo "binaries_0=bats"
        echo "binaries_count=1"
        echo "container_check=false"
    fi

    return 0
}

# Discover test suites in the project using BATS-specific patterns
# Usage: discover_test_suites <project_root> <framework_metadata>
# Returns: Test suites as flat data
# Behavior: Finds .bats files in common test directories (tests/bats/, test/bats/, etc.)
discover_test_suites() {
    local project_root="$1"
    local framework_metadata="$2"

    # Validate input
    if [[ -z "$project_root" ]] || [[ ! -d "$project_root" ]]; then
        echo "suites_count=0"
        return 0
    fi

    local suites_count=0
    local suite_index=0
    local results=""

    # Discover .bats files in common test directories
    # BATS tests are typically organized in tests/bats/ or test/bats/ directories
    local test_dirs=("$project_root/tests/bats" "$project_root/test/bats" "$project_root/tests" "$project_root/test")
    
    for test_dir in "${test_dirs[@]}"; do
        if [[ -d "$test_dir" ]]; then
            local bats_files
            bats_files=$(find "$test_dir" -name "*.bats" -type f 2>/dev/null)
            
            if [[ -n "$bats_files" ]]; then
                local file_count
                file_count=$(echo "$bats_files" | wc -l)
                
                if [[ $file_count -gt 0 ]]; then
                    # Create a suite for this directory
                    local suite_name
                    suite_name=$(basename "$test_dir")
                    
                    if [[ -z "$results" ]]; then
                        results="suites_${suite_index}_name=${suite_name}"
                    else
                        results="${results}"$'\n'"suites_${suite_index}_name=${suite_name}"
                    fi
                    results="${results}"$'\n'"suites_${suite_index}_framework=bats"
                    results="${results}"$'\n'"suites_${suite_index}_test_files_count=${file_count}"
                    
                    suites_count=$((suites_count + 1))
                    suite_index=$((suite_index + 1))
                    
                    # Only process first matching directory to avoid duplicates
                    break
                fi
            fi
        fi
    done

    # If no test directories found, search for .bats files anywhere
    if [[ $suites_count -eq 0 ]]; then
        local bats_files
        bats_files=$(find "$project_root" -maxdepth 3 -name "*.bats" -type f 2>/dev/null)
        
        if [[ -n "$bats_files" ]]; then
            local file_count
            file_count=$(echo "$bats_files" | wc -l)
            
            if [[ $file_count -gt 0 ]]; then
                results="suites_0_name=bats_tests"
                results="${results}"$'\n'"suites_0_framework=bats"
                results="${results}"$'\n'"suites_0_test_files_count=${file_count}"
                suites_count=1
            fi
        fi
    fi

    # Output results
    echo "suites_count=${suites_count}"
    if [[ -n "$results" ]]; then
        echo "$results"
    fi

    return 0
}

# Detect build requirements for BATS projects
# Usage: detect_build_requirements <project_root> <framework_metadata>
# Returns: Build requirements as flat data
detect_build_requirements() {
    local project_root="$1"
    local framework_metadata="$2"

    # BATS projects typically don't require building (scripts are interpreted)
    echo "requires_build=false"
    echo "build_steps_count=0"
    echo "build_commands_count=0"
    echo "build_dependencies_count=0"
    echo "build_artifacts_count=0"
    return 0
}

# Get build steps for containerized build
# Usage: get_build_steps <project_root> <build_requirements>
# Returns: Build steps as flat data
get_build_steps() {
    local project_root="$1"
    local build_requirements="$2"

    # Stub implementation (no build steps needed for BATS)
    echo "build_steps_count=0"
    return 0
}

# Execute test suite using BATS test runner
# Usage: execute_test_suite <test_suite> <test_image> <execution_config>
# Returns: Execution result as flat data
# Behavior: Executes bats command in container
execute_test_suite() {
    local test_suite="$1"
    local test_image="$2"
    local execution_config="$3"

    # Stub implementation (will be expanded in later phases)
    # For now, return basic structure
    echo "exit_code=0"
    echo "duration=0.0"
    echo "execution_method=docker"
    echo "test_command=bats"
    return 0
}

# Parse test results from BATS test output
# Usage: parse_test_results <output> <exit_code>
# Returns: Parsed results as flat data
# Behavior: Parses bats test output to extract test counts and status
parse_test_results() {
    local output="$1"
    local exit_code="$2"

    # Stub implementation (will be expanded in later phases)
    # For now, return basic structure based on exit code
    if [[ "$exit_code" == "0" ]]; then
        echo "total_tests=0"
        echo "passed_tests=0"
        echo "failed_tests=0"
        echo "skipped_tests=0"
        echo "test_details_count=0"
        echo "status=passed"
    else
        echo "total_tests=0"
        echo "passed_tests=0"
        echo "failed_tests=0"
        echo "skipped_tests=0"
        echo "test_details_count=0"
        echo "status=failed"
    fi

    return 0
}

# Get module metadata
# Usage: get_metadata
# Returns: Module metadata as flat data
get_metadata() {
    echo "module_type=framework"
    echo "language=bash"
    echo "frameworks_0=bats"
    echo "frameworks_count=1"
    echo "project_type=shell_script"
    echo "version=0.1.0"
    echo "capabilities_0=testing"
    echo "capabilities_count=1"
    echo "required_binaries_0=bats"
    echo "required_binaries_count=1"
    return 0
}


# End of: mod/frameworks/bats/mod.sh

# Included from: mod/frameworks/cargo/mod.sh
#!/usr/bin/env bash

# Suitey Cargo Framework Module
# Handles Cargo framework for Rust language
# Provides framework-specific test discovery, execution, and parsing for Cargo projects
#
# This module works in conjunction with the Rust language module:
# - Language module (mod/languages/rust/mod.sh) detects Rust language presence
# - Framework module (this module) handles Cargo-specific operations
# - Framework module has higher priority than language module for framework-specific operations

# Detect if Cargo project is present (framework-level detection)
# Usage: detect <project_root>
# Returns: Detection result as flat data
# Behavior: Checks for Cargo.toml (framework-specific indicator)
detect() {
    local project_root="$1"

    # Validate input
    if [[ -z "$project_root" ]] || [[ ! -d "$project_root" ]]; then
        echo "detected=false"
        echo "confidence=low"
        echo "indicators_count=0"
        echo "language=rust"
        echo "frameworks_0=cargo"
        return 0
    fi

    # Check for Cargo.toml file (primary Cargo indicator)
    if [[ -f "$project_root/Cargo.toml" ]]; then
        echo "detected=true"
        echo "confidence=high"
        echo "indicators_0=Cargo.toml"
        echo "indicators_count=1"
        echo "language=rust"
        echo "frameworks_0=cargo"
        return 0
    fi

    # Not detected
    echo "detected=false"
    echo "confidence=low"
    echo "indicators_count=0"
    echo "language=rust"
    echo "frameworks_0=cargo"
    return 0
}

# Check if required binaries are available
# Usage: check_binaries <project_root>
# Returns: Binary status as flat data
# Behavior: Checks for cargo binary in PATH and reports version if available
check_binaries() {
    local project_root="$1"

    # Check for cargo binary in PATH
    if command -v cargo >/dev/null 2>&1; then
        local cargo_version
        cargo_version=$(cargo --version 2>/dev/null | head -1 || echo "unknown")
        # Remove "cargo " prefix if present
        cargo_version="${cargo_version#cargo }"
        echo "available=true"
        echo "binaries_0=cargo"
        echo "binaries_count=1"
        echo "versions_cargo=$cargo_version"
        echo "container_check=false"
    else
        echo "available=false"
        echo "binaries_0=cargo"
        echo "binaries_count=1"
        echo "container_check=false"
    fi

    return 0
}

# Discover test suites in the project using Cargo-specific patterns
# Usage: discover_test_suites <project_root> <framework_metadata>
# Returns: Test suites as flat data
# Behavior: Finds unit tests in src/ and integration tests in tests/ directory
discover_test_suites() {
    local project_root="$1"
    local framework_metadata="$2"

    # Validate input
    if [[ -z "$project_root" ]] || [[ ! -d "$project_root" ]]; then
        echo "suites_count=0"
        return 0
    fi

    local suites_count=0
    local suite_index=0
    local results=""

    # Discover unit tests in src/ directory
    # Cargo unit tests are in files with #[cfg(test)] modules
    if [[ -d "$project_root/src" ]]; then
        local unit_test_files
        unit_test_files=$(find "$project_root/src" -name "*.rs" -type f 2>/dev/null | head -5)
        
        if [[ -n "$unit_test_files" ]]; then
            # Count files with test modules (simplified - just check if file exists)
            local unit_file_count
            unit_file_count=$(echo "$unit_test_files" | wc -l)
            
            if [[ $unit_file_count -gt 0 ]]; then
                if [[ -z "$results" ]]; then
                    results="suites_${suite_index}_name=unit_tests"
                else
                    results="${results}"$'\n'"suites_${suite_index}_name=unit_tests"
                fi
                results="${results}"$'\n'"suites_${suite_index}_framework=cargo"
                results="${results}"$'\n'"suites_${suite_index}_test_files_count=${unit_file_count}"
                
                suites_count=$((suites_count + 1))
                suite_index=$((suite_index + 1))
            fi
        fi
    fi

    # Discover integration tests in tests/ directory
    if [[ -d "$project_root/tests" ]]; then
        local integration_test_files
        integration_test_files=$(find "$project_root/tests" -name "*.rs" -type f 2>/dev/null)
        
        if [[ -n "$integration_test_files" ]]; then
            local integration_file_count
            integration_file_count=$(echo "$integration_test_files" | wc -l)
            
            if [[ $integration_file_count -gt 0 ]]; then
                if [[ -z "$results" ]]; then
                    results="suites_${suite_index}_name=integration_tests"
                else
                    results="${results}"$'\n'"suites_${suite_index}_name=integration_tests"
                fi
                results="${results}"$'\n'"suites_${suite_index}_framework=cargo"
                results="${results}"$'\n'"suites_${suite_index}_test_files_count=${integration_file_count}"
                
                suites_count=$((suites_count + 1))
            fi
        fi
    fi

    # Output results
    echo "suites_count=${suites_count}"
    if [[ -n "$results" ]]; then
        echo "$results"
    fi

    return 0
}

# Detect build requirements for Cargo projects
# Usage: detect_build_requirements <project_root> <framework_metadata>
# Returns: Build requirements as flat data
detect_build_requirements() {
    local project_root="$1"
    local framework_metadata="$2"

    # Cargo projects require building before testing
    echo "requires_build=true"
    echo "build_steps_count=1"
    echo "build_commands_0=cargo build --tests"
    echo "build_commands_count=1"
    echo "build_dependencies_count=0"
    echo "build_artifacts_count=0"
    return 0
}

# Get build steps for containerized build
# Usage: get_build_steps <project_root> <build_requirements>
# Returns: Build steps as flat data
get_build_steps() {
    local project_root="$1"
    local build_requirements="$2"

    # Check if building is required
    local requires_build
    requires_build=$(echo "$build_requirements" | grep "^requires_build=" | cut -d'=' -f2 || echo "false")

    if [[ "$requires_build" != "true" ]]; then
        echo "build_steps_count=0"
        return 0
    fi

    # Cargo build step (similar to Rust language module but framework-specific)
    # Note: Build execution happens in isolated Docker containers.
    # Project directory is mounted read-only (when volume mounts are configured).
    # Build artifacts are stored in container volumes, not in project directory.
    echo "build_steps_count=1"
    echo "build_steps_0_step_name=cargo_build"
    echo "build_steps_0_docker_image=rust:1.70-slim"
    echo "build_steps_0_build_command=cargo build --tests"
    echo "build_steps_0_working_directory=/workspace"
    echo "build_steps_0_volume_mounts_count=0"  # No volume mounts needed (project copied into container)
    echo "build_steps_0_volume_mounts_readonly=true"  # When mounts are used, they are read-only
    echo "build_steps_0_environment_variables_count=0"
    echo "build_steps_0_cpu_cores=0"  # Use all available cores

    return 0
}

# Execute test suite using Cargo test runner
# Usage: execute_test_suite <test_suite> <test_image> <execution_config>
# Returns: Execution result as flat data
# Behavior: Executes cargo test command in container
execute_test_suite() {
    local test_suite="$1"
    local test_image="$2"
    local execution_config="$3"

    # Stub implementation (will be expanded in later phases)
    # For now, return basic structure
    echo "exit_code=0"
    echo "duration=0.0"
    echo "execution_method=docker"
    echo "test_command=cargo test"
    return 0
}

# Parse test results from Cargo test output
# Usage: parse_test_results <output> <exit_code>
# Returns: Parsed results as flat data
# Behavior: Parses cargo test output to extract test counts and status
parse_test_results() {
    local output="$1"
    local exit_code="$2"

    # Stub implementation (will be expanded in later phases)
    # For now, return basic structure based on exit code
    if [[ "$exit_code" == "0" ]]; then
        echo "total_tests=0"
        echo "passed_tests=0"
        echo "failed_tests=0"
        echo "skipped_tests=0"
        echo "test_details_count=0"
        echo "status=passed"
    else
        echo "total_tests=0"
        echo "passed_tests=0"
        echo "failed_tests=0"
        echo "skipped_tests=0"
        echo "test_details_count=0"
        echo "status=failed"
    fi

    return 0
}

# Get module metadata
# Usage: get_metadata
# Returns: Module metadata as flat data
get_metadata() {
    echo "module_type=framework"
    echo "language=rust"
    echo "frameworks_0=cargo"
    echo "frameworks_count=1"
    echo "project_type=cargo_project"
    echo "version=0.1.0"
    echo "capabilities_0=testing"
    echo "capabilities_1=compilation"
    echo "capabilities_count=2"
    echo "required_binaries_0=cargo"
    echo "required_binaries_count=1"
    return 0
}


# End of: mod/frameworks/cargo/mod.sh

# Included from: mod/languages/bash/mod.sh
#!/usr/bin/env bash

# Suitey Bash Module
# Handles Bash language with BATS framework
# Provides detection, test discovery, build detection, and execution for Bash projects

# Detect if Bash/BATS project is present
# Usage: detect <project_root>
# Returns: Detection result as flat data
# Behavior: Checks for .bats files (high confidence), test directories (medium), or .sh files (low)
detect() {
    local project_root="$1"

    # Validate input
    if [[ -z "$project_root" ]] || [[ ! -d "$project_root" ]]; then
        echo "detected=false"
        echo "confidence=low"
        echo "indicators_count=0"
        echo "language=bash"
        echo "frameworks_0=bats"
        return 0
    fi

    # Check for .bats files (primary indicator - highest confidence)
    # Look in common test directories: tests/bats/, test/bats/, tests/, test/
    local bats_files
    bats_files=$(find "$project_root" -maxdepth 3 -name "*.bats" -type f 2>/dev/null | head -1)
    if [[ -n "$bats_files" ]]; then
        echo "detected=true"
        echo "confidence=high"
        echo "indicators_0=bats_test_files"
        echo "indicators_count=1"
        echo "language=bash"
        echo "frameworks_0=bats"
        return 0
    fi

    # Check for BATS test directory structure (secondary indicator - medium confidence)
    if [[ -d "$project_root/tests/bats" ]] || [[ -d "$project_root/test/bats" ]]; then
        echo "detected=true"
        echo "confidence=medium"
        echo "indicators_0=bats_test_directory"
        echo "indicators_count=1"
        echo "language=bash"
        echo "frameworks_0=bats"
        return 0
    fi

    # Check for .sh files with bash shebang (weak indicator - low confidence)
    # Only check in top-level directories to avoid false positives
    local sh_files
    sh_files=$(find "$project_root" -maxdepth 2 -name "*.sh" -type f 2>/dev/null | head -1)
    if [[ -n "$sh_files" ]]; then
        # Check if file has bash shebang
        if head -1 "$sh_files" 2>/dev/null | grep -q "#!/usr/bin/env bash\|#!/bin/bash"; then
            echo "detected=true"
            echo "confidence=low"
            echo "indicators_0=bash_script_files"
            echo "indicators_count=1"
            echo "language=bash"
            echo "frameworks_0=bats"
            return 0
        fi
    fi

    # Not detected
    echo "detected=false"
    echo "confidence=low"
    echo "indicators_count=0"
    echo "language=bash"
    echo "frameworks_0=bats"
    return 0
}

# Check if required binaries are available
# Usage: check_binaries <project_root>
# Returns: Binary status as flat data
# Behavior: Checks for bats binary in PATH and reports version if available
check_binaries() {
    local project_root="$1"

    # Check for bats binary in PATH
    if command -v bats >/dev/null 2>&1; then
        local bats_version
        bats_version=$(bats --version 2>/dev/null | head -1 || echo "unknown")
        # Remove "bats " prefix if present
        bats_version="${bats_version#bats }"
        echo "available=true"
        echo "binaries_0=bats"
        echo "binaries_count=1"
        echo "versions_bats=$bats_version"
        echo "container_check=false"
    else
        echo "available=false"
        echo "binaries_0=bats"
        echo "binaries_count=1"
        echo "container_check=false"
    fi

    return 0
}

# Discover test suites in the project
# Usage: discover_test_suites <project_root> <framework_metadata>
# Returns: Test suites as flat data
discover_test_suites() {
    local project_root="$1"
    local framework_metadata="$2"

    # BATS tests are typically in tests/bats/ or test/bats/ directories
    # For now, return empty (stub implementation)
    echo "suites_count=0"
    return 0
}

# Detect build requirements
# Usage: detect_build_requirements <project_root> <framework_metadata>
# Returns: Build requirements as flat data
detect_build_requirements() {
    local project_root="$1"
    local framework_metadata="$2"

    # Bash projects typically don't require building (scripts are interpreted)
    echo "requires_build=false"
    echo "build_steps_count=0"
    echo "build_commands_count=0"
    echo "build_dependencies_count=0"
    echo "build_artifacts_count=0"
    return 0
}

# Get build steps for containerized build
# Usage: get_build_steps <project_root> <build_requirements>
# Returns: Build steps as flat data
get_build_steps() {
    local project_root="$1"
    local build_requirements="$2"

    # Stub implementation (no build steps needed for Bash)
    echo "build_steps_count=0"
    return 0
}

# Execute test suite
# Usage: execute_test_suite <test_suite> <test_image> <execution_config>
# Returns: Execution result as flat data
execute_test_suite() {
    local test_suite="$1"
    local test_image="$2"
    local execution_config="$3"

    # Stub implementation
    echo "exit_code=0"
    echo "duration=0.0"
    echo "execution_method=docker"
    return 0
}

# Parse test results from framework output
# Usage: parse_test_results <output> <exit_code>
# Returns: Parsed results as flat data
parse_test_results() {
    local output="$1"
    local exit_code="$2"

    # Stub implementation
    echo "total_tests=0"
    echo "passed_tests=0"
    echo "failed_tests=0"
    echo "skipped_tests=0"
    echo "test_details_count=0"
    echo "status=passed"
    return 0
}

# Get module metadata
# Usage: get_metadata
# Returns: Module metadata as flat data
get_metadata() {
    echo "module_type=language"
    echo "language=bash"
    echo "frameworks_0=bats"
    echo "frameworks_count=1"
    echo "project_type=shell_script"
    echo "version=0.1.0"
    echo "capabilities_0=testing"
    echo "capabilities_count=1"
    echo "required_binaries_0=bats"
    echo "required_binaries_count=1"
    return 0
}


# End of: mod/languages/bash/mod.sh

# Included from: mod/languages/rust/mod.sh
#!/usr/bin/env bash

# Suitey Rust Module
# Handles Rust language with Cargo framework
# Provides detection, test discovery, build detection, and execution for Rust projects

# Detect if Rust/Cargo project is present
# Usage: detect <project_root>
# Returns: Detection result as flat data
# Behavior: Checks for Cargo.toml (high confidence), Cargo.lock (medium), or .rs files (low)
detect() {
    local project_root="$1"

    # Validate input
    if [[ -z "$project_root" ]] || [[ ! -d "$project_root" ]]; then
        echo "detected=false"
        echo "confidence=low"
        echo "indicators_count=0"
        echo "language=rust"
        echo "frameworks_0=cargo"
        return 0
    fi

    # Check for Cargo.toml file (primary indicator - highest confidence)
    if [[ -f "$project_root/Cargo.toml" ]]; then
        echo "detected=true"
        echo "confidence=high"
        echo "indicators_0=Cargo.toml"
        echo "indicators_count=1"
        echo "language=rust"
        echo "frameworks_0=cargo"
        return 0
    fi

    # Check for Cargo.lock (secondary indicator - medium confidence)
    if [[ -f "$project_root/Cargo.lock" ]]; then
        echo "detected=true"
        echo "confidence=medium"
        echo "indicators_0=Cargo.lock"
        echo "indicators_count=1"
        echo "language=rust"
        echo "frameworks_0=cargo"
        return 0
    fi

    # Check for .rs files (weak indicator - low confidence)
    # Only check in top-level directories to avoid false positives
    if find "$project_root" -maxdepth 2 -name "*.rs" -type f 2>/dev/null | head -1 | grep -q .; then
        echo "detected=true"
        echo "confidence=low"
        echo "indicators_0=rust_source_files"
        echo "indicators_count=1"
        echo "language=rust"
        echo "frameworks_0=cargo"
        return 0
    fi

    # Not detected
    echo "detected=false"
    echo "confidence=low"
    echo "indicators_count=0"
    echo "language=rust"
    echo "frameworks_0=cargo"
    return 0
}

# Check if required binaries are available
# Usage: check_binaries <project_root>
# Returns: Binary status as flat data
# Behavior: Checks for cargo binary in PATH and reports version if available
check_binaries() {
    local project_root="$1"

    # Check for cargo binary in PATH
    if command -v cargo >/dev/null 2>&1; then
        local cargo_version
        cargo_version=$(cargo --version 2>/dev/null | head -1 || echo "unknown")
        # Remove "cargo " prefix if present
        cargo_version="${cargo_version#cargo }"
        echo "available=true"
        echo "binaries_0=cargo"
        echo "binaries_count=1"
        echo "versions_cargo=$cargo_version"
        echo "container_check=false"
    else
        echo "available=false"
        echo "binaries_0=cargo"
        echo "binaries_count=1"
        echo "container_check=false"
    fi

    return 0
}

# Discover test suites in the project
# Usage: discover_test_suites <project_root> <framework_metadata>
# Returns: Test suites as flat data
discover_test_suites() {
    local project_root="$1"
    local framework_metadata="$2"

    # Cargo tests are typically in src/ or tests/ directories
    # For now, return empty (stub implementation)
    echo "suites_count=0"
    return 0
}

# Detect build requirements
# Usage: detect_build_requirements <project_root> <framework_metadata>
# Returns: Build requirements as flat data
detect_build_requirements() {
    local project_root="$1"
    local framework_metadata="$2"

    # Rust projects typically require building before testing
    echo "requires_build=true"
    echo "build_steps_count=1"
    echo "build_commands_0=cargo build --tests"
    echo "build_commands_count=1"
    echo "build_dependencies_count=0"
    echo "build_artifacts_count=0"
    return 0
}

# Get build steps for containerized build
# Usage: get_build_steps <project_root> <build_requirements>
# Returns: Build steps as flat data
get_build_steps() {
    local project_root="$1"
    local build_requirements="$2"

    # Check if building is required
    local requires_build
    requires_build=$(echo "$build_requirements" | grep "^requires_build=" | cut -d'=' -f2 || echo "false")

    if [[ "$requires_build" != "true" ]]; then
        echo "build_steps_count=0"
        return 0
    fi

    # Rust build step
    # Note: Build execution happens in isolated Docker containers.
    # Project directory is mounted read-only (when volume mounts are configured).
    # Build artifacts are stored in container volumes, not in project directory.
    echo "build_steps_count=1"
    echo "build_steps_0_step_name=rust_build"
    echo "build_steps_0_docker_image=rust:1.70-slim"
    echo "build_steps_0_build_command=cargo build --tests"
    echo "build_steps_0_working_directory=/workspace"
    echo "build_steps_0_volume_mounts_count=0"  # No volume mounts needed (project copied into container)
    echo "build_steps_0_volume_mounts_readonly=true"  # When mounts are used, they are read-only
    echo "build_steps_0_environment_variables_count=0"
    echo "build_steps_0_cpu_cores=0"  # Use all available cores

    return 0
}

# Execute test suite
# Usage: execute_test_suite <test_suite> <test_image> <execution_config>
# Returns: Execution result as flat data
execute_test_suite() {
    local test_suite="$1"
    local test_image="$2"
    local execution_config="$3"

    # Stub implementation
    echo "exit_code=0"
    echo "duration=0.0"
    echo "execution_method=docker"
    return 0
}

# Parse test results from framework output
# Usage: parse_test_results <output> <exit_code>
# Returns: Parsed results as flat data
parse_test_results() {
    local output="$1"
    local exit_code="$2"

    # Stub implementation
    echo "total_tests=0"
    echo "passed_tests=0"
    echo "failed_tests=0"
    echo "skipped_tests=0"
    echo "test_details_count=0"
    echo "status=passed"
    return 0
}

# Get module metadata
# Usage: get_metadata
# Returns: Module metadata as flat data
get_metadata() {
    echo "module_type=language"
    echo "language=rust"
    echo "frameworks_0=cargo"
    echo "frameworks_count=1"
    echo "project_type=cargo"
    echo "version=0.1.0"
    echo "capabilities_0=testing"
    echo "capabilities_1=compilation"
    echo "capabilities_count=2"
    echo "required_binaries_0=cargo"
    echo "required_binaries_count=1"
    return 0
}


# End of: mod/languages/rust/mod.sh

# Included from: mod/tools/shellcheck/mod.sh
#!/usr/bin/env bash

# Suitey Tool Module: ShellCheck
# Orchestrates ShellCheck for shell script code quality analysis
# No external dependencies

# Detect if ShellCheck should be run on this project
# Looks for shell scripts (.sh files) in the project
detect() {
    local project_root="$1"

    # Check if project root exists and is readable
    if [[ ! -d "$project_root" || ! -r "$project_root" ]]; then
        echo "detected=false"
        echo "confidence=low"
        echo "indicators_count=0"
        return 0
    fi

    # Look for shell scripts (.sh files)
    local shell_files
    shell_files=$(find "$project_root" -name "*.sh" -type f 2>/dev/null | head -10)

    if [[ -n "$shell_files" ]]; then
        local file_count
        file_count=$(echo "$shell_files" | wc -l)

        echo "detected=true"
        echo "confidence=high"
        echo "indicators_count=1"
        echo "indicators_0=$file_count shell script files found"
        echo "language=shell"
        echo "frameworks_count=0"
    else
        echo "detected=false"
        echo "confidence=low"
        echo "indicators_count=0"
    fi
}

# Check if required binaries are available
# For ShellCheck, this is typically handled in containers
check_binaries() {
    echo "available=true"
    echo "binaries_count=0"
}

# Discover test suites (shell scripts to check)
discover_test_suites() {
    local project_root="$1"
    local framework_metadata="$2"

    # Find all shell scripts in the project
    local shell_files
    shell_files=$(find "$project_root" -name "*.sh" -type f 2>/dev/null)

    if [[ -z "$shell_files" ]]; then
        echo "suites_count=0"
        return 0
    fi

    local file_count=0
    local suite_index=0

    # Group shell scripts into a single suite for efficiency
    echo "suites_count=1"
    echo "suites_0_name=shellcheck"
    echo "suites_0_framework=code-quality"
    echo "suites_0_metadata_0=container_image=koalaman/shellcheck:latest"
    echo "suites_0_metadata_1=command=shellcheck --format=json"
    echo "suites_0_metadata_count=2"
    echo "suites_0_execution_config_count=0"

    # Add all shell files to the suite
    while IFS= read -r file; do
        if [[ -f "$file" && -r "$file" ]]; then
            echo "suites_0_test_files_$file_count=$file"
            ((file_count++))
        fi
    done <<< "$shell_files"

    echo "suites_0_test_files_count=$file_count"
}

# Detect build requirements
# ShellCheck doesn't require building
detect_build_requirements() {
    local project_root="$1"
    local framework_metadata="$2"

    echo "requires_build=false"
    echo "build_steps_count=0"
    echo "build_commands_count=0"
    echo "build_dependencies_count=0"
    echo "build_artifacts_count=0"
}

# Get build steps
# No build steps needed for ShellCheck
get_build_steps() {
    local project_root="$1"
    local build_requirements="$2"

    echo "build_steps_count=0"
}

# Execute test suite (run ShellCheck)
execute_test_suite() {
    local test_suite="$1"
    local test_image="$2"
    local execution_config="$3"

    # For now, return a mock result
    # In real implementation, this would run ShellCheck in a Docker container
    echo "exit_code=0"
    echo "duration=1.2"
    echo "output=[]"
    echo "container_id=mock-container-123"
    echo "execution_method=docker"
    echo "test_image=koalaman/shellcheck:latest"
}

# Parse test results from ShellCheck JSON output
parse_test_results() {
    local output="$1"
    local exit_code="$2"

    # Parse ShellCheck JSON output
    # For now, return mock results
    # In real implementation, this would parse actual JSON output
    if [[ $exit_code -eq 0 ]]; then
        echo "total_tests=1"
        echo "passed_tests=1"
        echo "failed_tests=0"
        echo "skipped_tests=0"
        echo "test_details_count=0"
        echo "status=passed"
    else
        echo "total_tests=1"
        echo "passed_tests=0"
        echo "failed_tests=1"
        echo "skipped_tests=0"
        echo "test_details_0=Shell script contains issues"
        echo "test_details_count=1"
        echo "status=failed"
    fi
}

# Get module metadata
get_metadata() {
    echo "module_type=tool"
    echo "language=shell"
    echo "frameworks_count=0"
    echo "project_type=code-quality"
    echo "version=0.1.0"
    echo "capabilities_0=code-quality"
    echo "capabilities_count=1"
    echo "required_binaries_count=0"
}
# End of: mod/tools/shellcheck/mod.sh

# Main Suitey functionality will be added here

# Exit code constants
# 0 = success
# 1 = tests failed (for future use)
# 2 = suitey error (invalid arguments, internal errors, etc.)
readonly EXIT_SUCCESS=0
readonly EXIT_TESTS_FAILED=1
readonly EXIT_SUITEY_ERROR=2

show_help() {
    cat << 'HELP_EOF'
Suitey v0.1.0 - Cross-platform test runner

Usage: suitey.sh [OPTIONS] [COMMAND]

DESCRIPTION
    Suitey is a cross-platform test runner that automatically detects test suites,
    builds projects, and executes tests in isolated Docker containers.

OPTIONS
    -h, --help          Show this help message and exit
    -v, --version       Show version information and exit

COMMANDS
    (Commands will be implemented in future phases)

EXAMPLES
    suitey.sh --help          Show help information
    suitey.sh --version       Show version information
    suitey.sh                 Show help (default behavior)

For more information, see the Suitey documentation.
HELP_EOF
}

show_version() {
    echo "Suitey v0.1.0"
    echo "Build system functional - ready for implementation"
}

# Run all environment validation checks
# Returns 0 if all checks pass, 1 if any check fails
run_environment_checks() {
    local check_failed=0

    # Run all environment checks
    if ! check_bash_version; then
        check_failed=1
    fi

    if ! check_docker_installed; then
        check_failed=1
    fi

    if ! check_docker_daemon_running; then
        check_failed=1
    fi

    if ! check_tmp_writable; then
        check_failed=1
    fi

    # Return failure if any check failed
    if [[ $check_failed -eq 1 ]]; then
        return 1
    fi

    return 0
}

# Validate and normalize directory path
# Returns normalized absolute path on success, exits with error on failure
validate_directory() {
    local dir_path="$1"
    local original_path="$1"
    
    # Check if directory exists first (before normalization)
    if [[ ! -e "$dir_path" ]]; then
        echo "Error: Directory does not exist: $original_path" >&2
        echo "Run '$0 --help' for usage information." >&2
        return 1
    fi
    
    # Check if it's actually a directory (not a file)
    if [[ ! -d "$dir_path" ]]; then
        echo "Error: Path is not a directory: $original_path" >&2
        echo "Run '$0 --help' for usage information." >&2
        return 1
    fi
    
    # Normalize path: resolve to absolute path
    # Use cd to resolve symlinks and normalize . and ..
    local normalized_path
    if normalized_path="$(cd "$dir_path" 2>/dev/null && pwd)"; then
        dir_path="$normalized_path"
    else
        # If cd failed, try to construct absolute path
        if [[ "$dir_path" != /* ]]; then
            # Relative path - make absolute
            dir_path="$(pwd)/$dir_path"
        fi
    fi
    
    # Check if directory is readable
    if [[ ! -r "$dir_path" ]]; then
        echo "Error: Directory is not readable: $original_path" >&2
        echo "Run '$0 --help' for usage information." >&2
        return 1
    fi
    
    # Return normalized absolute path
    echo "$dir_path"
    return 0
}

main() {
    local target_directory=""
    
    # Parse command-line arguments
    # Options take precedence over directory arguments
    while [[ $# -gt 0 ]]; do
        case "$1" in
            -h|--help)
                show_help
                exit $EXIT_SUCCESS
                ;;
            -v|--version)
                show_version
                exit $EXIT_SUCCESS
                ;;
            -*)
                # Unknown option
                echo "Error: Unknown option '$1'" >&2
                echo "Run '$0 --help' for usage information." >&2
                exit $EXIT_SUITEY_ERROR
                ;;
            *)
                # Non-option argument - treat as directory
                if [[ -n "$target_directory" ]]; then
                    echo "Error: Multiple directory arguments provided. Please specify only one directory." >&2
                    echo "Run '$0 --help' for usage information." >&2
                    exit $EXIT_SUITEY_ERROR
                fi
                target_directory="$1"
                ;;
        esac
        shift
    done
    
    # If no arguments provided, show help
    if [[ -z "$target_directory" ]]; then
        show_help
        exit $EXIT_SUCCESS
    fi
    
    # Validate directory
    local normalized_dir
    normalized_dir=$(validate_directory "$target_directory")
    if [[ $? -ne 0 ]]; then
        exit $EXIT_SUITEY_ERROR
    fi
    
    # Run environment checks before execution
    if ! run_environment_checks; then
        echo "" >&2
        echo "Environment validation failed. Please fix the issues above and try again." >&2
        exit $EXIT_SUITEY_ERROR
    fi
    
    # Register built-in modules
    # These are the core language and framework modules included in the bundle
    if [[ -f "mod/languages/rust/mod.sh" ]]; then
        source "mod/languages/rust/mod.sh" 2>/dev/null || true
        register_module "rust-module" "rust-module" 2>/dev/null || true
    fi

    if [[ -f "mod/languages/bash/mod.sh" ]]; then
        source "mod/languages/bash/mod.sh" 2>/dev/null || true
        register_module "bash-module" "bash-module" 2>/dev/null || true
    fi

    if [[ -f "mod/frameworks/cargo/mod.sh" ]]; then
        source "mod/frameworks/cargo/mod.sh" 2>/dev/null || true
        register_module "cargo-module" "cargo-module" 2>/dev/null || true
    fi

    if [[ -f "mod/frameworks/bats/mod.sh" ]]; then
        source "mod/frameworks/bats/mod.sh" 2>/dev/null || true
        register_module "bats-module" "bats-module" 2>/dev/null || true
    fi

    if [[ -f "mod/tools/shellcheck/mod.sh" ]]; then
        source "mod/tools/shellcheck/mod.sh" 2>/dev/null || true
        register_module "shellcheck-module" "shellcheck-module" 2>/dev/null || true
    fi

    # Perform platform detection
    echo "Suitey v0.1.0"
    echo "Analyzing project: $normalized_dir"
    echo ""

    # Detect platforms in the target directory
    local detection_results
    detection_results=$(detect_platforms "$normalized_dir" 2>/dev/null || echo "platforms_count=0")

    # Display container environment status
    echo "Container Environment:"
    if echo "$detection_results" | grep -q "docker_command_available=true"; then
        echo "   Docker command available"
    else
        echo "   Docker command not found"
    fi

    if echo "$detection_results" | grep -q "docker_daemon_available=true"; then
        echo "   Docker daemon running"
    else
        echo "   Docker daemon not accessible"
    fi

    if echo "$detection_results" | grep -q "container_operations=true"; then
        echo "   Container operations functional"
    else
        echo "   Container operations failed"
    fi

    if echo "$detection_results" | grep -q "network_access=true"; then
        echo "   Network access available"
    else
        echo "   Network access issues"
    fi

    # Display warnings if any
    local warning_count
    warning_count=$(echo "$detection_results" | grep "^docker_warnings_count=" | cut -d'=' -f2)
    if [[ "$warning_count" -gt 0 ]]; then
        echo ""
        echo "Warnings:"
        local i=0
        while [[ $i -lt "$warning_count" ]]; do
            local warning
            warning=$(echo "$detection_results" | grep "^docker_warnings_${i}=" | cut -d'=' -f2-)
            if [[ -n "$warning" ]]; then
                echo "   $warning"
            fi
            ((i++))
        done
    fi

    echo ""
    echo "Platform Detection:"

    # Get platform count
    local platforms_count
    platforms_count=$(echo "$detection_results" | grep "^platforms_count=" | cut -d'=' -f2)

    if [[ "$platforms_count" -eq 0 ]]; then
        echo "  No supported platforms detected in this project."
        echo ""
        echo "Supported platforms:"
        echo "  - Rust (Cargo.toml projects)"
        echo "  - Bash (BATS test projects)"
        exit $EXIT_SUCCESS
    fi

    # Display detected platforms
    # Collect unique language+framework combinations with highest confidence
    local detected_projects=""
    local i=0
    while [[ $i -lt "$platforms_count" ]]; do
        local language
        local framework
        local confidence
        local module_type

        language=$(echo "$detection_results" | grep "^platforms_${i}_language=" | head -1 | cut -d'=' -f2)
        framework=$(echo "$detection_results" | grep "^platforms_${i}_framework=" | head -1 | cut -d'=' -f2)
        confidence=$(echo "$detection_results" | grep "^platforms_${i}_confidence=" | head -1 | cut -d'=' -f2)
        module_type=$(echo "$detection_results" | grep "^platforms_${i}_module_type=" | head -1 | cut -d'=' -f2)

        if [[ -n "$language" ]]; then
            local project_key="$language"
            if [[ -n "$framework" ]]; then
                project_key="$project_key-$framework"
            fi

            # Check if we already have this project combination
            if ! echo "$detected_projects" | grep -q "^$project_key:"; then
                # New project combination
                detected_projects="${detected_projects}$project_key:$confidence:$framework"$'\n'
                echo "   $language project detected (confidence: $confidence)"
                if [[ -n "$framework" ]]; then
                    echo "    Framework: $framework"
                fi
            fi
        fi

        ((i++))
    done

    echo ""
    echo "Full workflow execution will be implemented in future phases."
    exit $EXIT_SUCCESS
}

# Run main function
main "$@"
